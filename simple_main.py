import os
import sys
import uvicorn
import traceback
from dotenv import load_dotenv
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from fastapi.requests import Request
from fastapi.exceptions import HTTPException

# =================================================================
# 1. ğŸš€ å¼ºåˆ¶åŠ è½½ç¯å¢ƒå˜é‡ (ä» Dockerfile é…ç½®è¯»å–ï¼Œæ— éœ€ .env æ–‡ä»¶)
# =================================================================
def _load_env_from_dockerfile():
    """
    ä» backend/Dockerfile è¯»å–ç¯å¢ƒå˜é‡é…ç½®

    ã€ä¿®å¤ã€‘ä¼˜å…ˆä½¿ç”¨å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡ï¼ˆDockerfile ENV é…ç½®ï¼‰
    åªæœ‰åœ¨ç¯å¢ƒå˜é‡æœªè®¾ç½®æ—¶ï¼Œæ‰ä½¿ç”¨è¿™é‡Œçš„é»˜è®¤å€¼
    """
    # é»˜è®¤é…ç½®ï¼ˆä»…åœ¨ç¯å¢ƒå˜é‡æœªè®¾ç½®æ—¶ä½¿ç”¨ï¼‰
    default_config = {
        # ==================== ç¯å¢ƒé…ç½® ====================
        "ENVIRONMENT": "development",
        "DEFAULT_ADMIN_PASSWORD": "admin123",

        # ==================== Redis é…ç½® ====================
        "REDIS_HOST": "redis7.gms.svc.cluster.local",
        "REDIS_PORT": "6379",
        "REDIS_DB": "0",
        "REDIS_URL": "redis://redis7.gms.svc.cluster.local:6379/0",

        # ==================== PostgreSQL æ•°æ®åº“é…ç½® ====================
        "POSTGRES_SERVER": "postgres18-0.postgres18.gms.svc.cluster.local",
        "POSTGRES_PORT": "5432",
        "POSTGRES_DB": "legal_assistant_db",
        "POSTGRES_USER": "postgres",
        "POSTGRES_PASSWORD": "postgres",
        "DATABASE_URL": "postgresql://postgres:postgres@postgres18-0.postgres18.gms.svc.cluster.local:5432/legal_assistant_db",

        # ==================== åº”ç”¨å¯†é’¥é…ç½® ====================
        "SECRET_KEY": "a_very_long_and_super_secret_random_string_that_is_hard_to_guess",
        "ACCESS_TOKEN_EXPIRE_MINUTES": "1440",

        # ==================== ONLYOFFICE é…ç½® ====================
        "ONLYOFFICE_JWT_SECRET": "legal_doc_secret_2025",
        "BACKEND_PUBLIC_URL": "http://localhost:8000",

        # ==================== Dify é…ç½® (æš‚æ—¶ç¦ç”¨) ====================
        "DIFY_ENABLED": "false",
        "DIFY_GUIDANCE_ANALYSIS_ENABLED": "false",
        "DIFY_EXPERT_CONSULTATION_ENABLED": "false",

        # ==================== DeepSeek API é…ç½® ====================
        "DEEPSEEK_API_KEY": "7adb34bf-3cb3-4dea-af41-b79de8c08ca3",  # æœ¬åœ°å¼€å‘é»˜è®¤å€¼ï¼Œç”Ÿäº§ç¯å¢ƒä¼šè¢« Dockerfile ENV è¦†ç›–
        "DEEPSEEK_API_URL": "https://sd4a58h819ma6giel1ck0.apigateway-cn-beijing.volceapi.com/v1",
        "DEEPSEEK_MODEL": "deepseek-chat",
        "DEEPSEEK_TEMPERATURE": "0.7",
        "DEEPSEEK_MAX_TOKENS": "2000",
        "DEEPSEEK_TIMEOUT": "60",

        # ==================== LangChain API é…ç½® (é£é™©è¯„ä¼°ç­‰æ ¸å¿ƒåŠŸèƒ½) ====================
        "LANGCHAIN_API_KEY": "7adb34bf-3cb3-4dea-af41-b79de8c08ca3",
        "LANGCHAIN_API_BASE_URL": "https://sd4a58h819ma6giel1ck0.apigateway-cn-beijing.volceapi.com/v1",
        "MODEL_NAME": "Qwen3-235B-A22B-Thinking-2507",

        # ==================== OpenAI API é…ç½® (åˆåŒç”Ÿæˆæ¨¡å—) ====================
        "OPENAI_API_KEY": "7adb34bf-3cb3-4dea-af41-b79de8c08ca3",
        "OPENAI_API_BASE": "https://sd4a58h819ma6giel1ck0.apigateway-cn-beijing.volceapi.com/v1",

        # ==================== MinerU PDF è§£ææœåŠ¡é…ç½® ====================
        "MINERU_API_URL": "http://115.190.40.198:7231/v2/parse/file",
        "MINERU_API_TIMEOUT": "120",
        "MINERU_ENABLED": "true",

        # ==================== OCR æœåŠ¡é…ç½® ====================
        "OCR_API_URL": "http://115.190.43.141:8002/ocr/v1/recognize-text",
        "OCR_API_TIMEOUT": "60",
        "OCR_ENABLED": "true",

        # ==================== AI æ–‡æ¡£é¢„å¤„ç†é…ç½® ====================
        "AI_POSTPROCESS_ENABLED": "true",
        "AI_POSTPROCESS_MODEL": "qwen3-vl:32b-thinking-q8_0",
        "AI_POSTPROCESS_API_URL": "https://sd4a58h819ma6giel1ck0.apigateway-cn-beijing.volceapi.com/v1",
        "AI_POSTPROCESS_API_KEY": "7adb34bf-3cb3-4dea-af41-b79de8c08ca3",
        "AI_AUTH_TYPE": "bearer",
        "AI_POSTPROCESS_TIMEOUT": "30",
        "AI_POSTPROCESS_BATCH_SIZE": "5",
        "AI_POSTPROCESS_CONFIDENCE_THRESHOLD": "0.7",
        "AI_POSTPROCESS_ONLY_AMBIGUOUS": "true",

        # ==================== Qwen3-235B-A22B-Thinking-2507 æ¨¡å‹é…ç½® ====================
        "QWEN3_THINKING_API_KEY": "7adb34bf-3cb3-4dea-af41-b79de8c08ca3",
        "QWEN3_THINKING_API_URL": "https://sd4a58h819ma6giel1ck0.apigateway-cn-beijing.volceapi.com/v1",
        "QWEN3_THINKING_MODEL": "Qwen3-235B-A22B-Thinking-2507",
        "QWEN3_THINKING_TIMEOUT": "120",
        "QWEN3_THINKING_ENABLED": "true",

        # ==================== GPT-OSS-120B æ¨¡å‹é…ç½® ====================
        "GPT_OSS_120B_API_URL": "http://101.126.134.56:11434/v1",
        "GPT_OSS_120B_MODEL": "gpt-oss:120b",

        # ==================== BGE åµŒå…¥æ¨¡å‹é…ç½® (å‘é‡æ£€ç´¢) ====================
        "BGE_EMBEDDING_API_URL": "http://115.190.43.141:11434/api/embed",
        "BGE_RERANKER_API_URL": "http://115.190.43.141:9997/v1/rerank",
        "BGE_MODEL_NAME": "bge-m3",
        "BGE_EMBEDDING_DIM": "1024",
        "BGE_TIMEOUT": "30",

        # ==================== Celery ä»»åŠ¡é˜Ÿåˆ—é…ç½® ====================
        "CELERY_BROKER_URL": "redis://redis:6379/0",
        "CELERY_RESULT_BACKEND": "redis://redis:6379/0",
        "CELERY_ENABLED": "true",
        "CELERY_TASK_TRACK_STARTED": "true",
        "CELERY_TASK_TIME_LIMIT": "3600",
        "CELERY_TASK_SOFT_TIME_LIMIT": "3300",

        # ==================== Flower ç›‘æ§é…ç½® ====================
        "FLOWER_PORT": "5556",

        # ==================== å‘é‡æ•°æ®åº“é…ç½® ====================
        "CHROMA_PERSIST_DIR": "./storage/chroma_db",
        "VECTOR_DB_TYPE": "chroma",
    }

    # è®¾ç½®ç¯å¢ƒå˜é‡åˆ° os.environ
    # ã€ä¿®å¤ã€‘ä¼˜å…ˆä½¿ç”¨å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡ï¼ˆDockerfile ENV é…ç½®ï¼‰
    # åªæœ‰åœ¨ç¯å¢ƒå˜é‡æœªè®¾ç½®æ—¶ï¼Œæ‰ä½¿ç”¨è¿™é‡Œçš„é»˜è®¤å€¼
    set_count = 0
    for key, value in default_config.items():
        if key not in os.environ or os.environ[key] == "":
            os.environ[key] = value
            set_count += 1

    print(f"âœ… ç¯å¢ƒå˜é‡åŠ è½½å®Œæˆ: {set_count} ä¸ªä½¿ç”¨é»˜è®¤å€¼, {len(default_config) - set_count} ä¸ªä½¿ç”¨ Dockerfile ENV é…ç½®")

# æ‰§è¡Œç¯å¢ƒå˜é‡åŠ è½½
_load_env_from_dockerfile()

# ğŸ” è°ƒè¯•ï¼šæ‰“å°å…³é”®ç¯å¢ƒå˜é‡ï¼ˆç”¨äºæ’æŸ¥é—®é¢˜ï¼‰
print("=" * 60)
print("[è°ƒè¯•] å…³é”®ç¯å¢ƒå˜é‡æ£€æŸ¥:")
print(f"  OPENAI_API_KEY: {'âœ… å·²è®¾ç½®' if os.getenv('OPENAI_API_KEY') else 'âŒ æœªè®¾ç½®'}")
print(f"  DEEPSEEK_API_KEY: {'âœ… å·²è®¾ç½®' if os.getenv('DEEPSEEK_API_KEY') else 'âŒ æœªè®¾ç½®'}")
print(f"  LANGCHAIN_API_KEY: {'âœ… å·²è®¾ç½®' if os.getenv('LANGCHAIN_API_KEY') else 'âŒ æœªè®¾ç½®'}")
print(f"  QWEN3_THINKING_API_KEY: {'âœ… å·²è®¾ç½®' if os.getenv('QWEN3_THINKING_API_KEY') else 'âŒ æœªè®¾ç½®'}")
print("=" * 60)

# é¢å¤–ï¼šä¹Ÿå°è¯•åŠ è½½ .env æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼Œå¯ä»¥è¦†ç›– Dockerfile é…ç½®ï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
env_path = os.path.join(current_dir, ".env")
from dotenv import load_dotenv
load_dotenv(dotenv_path=env_path, verbose=True, override=False)  # ä¸è¦†ç›–å·²è®¾ç½®çš„å€¼

# =================================================================
# 2. ğŸ› ï¸ ä¿®æ­£ Python æœç´¢è·¯å¾„
# =================================================================
backend_path = os.path.join(current_dir, "backend")
sys.path.insert(0, backend_path)

# =================================================================
# 2.5 ğŸ—„ï¸ æ•°æ®åº“åˆå§‹åŒ–ï¼ˆåœ¨å¯¼å…¥ app.main ä¹‹å‰æ‰§è¡Œï¼‰
# =================================================================
def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“å’Œè¡¨"""
    try:
        import psycopg2
        from urllib.parse import urlparse

        # è§£æ DATABASE_URL
        db_url = os.getenv("DATABASE_URL", "")
        if not db_url:
            print("âš ï¸  è­¦å‘Š: DATABASE_URL æœªè®¾ç½®ï¼Œè·³è¿‡æ•°æ®åº“åˆå§‹åŒ–")
            return False

        parsed = urlparse(db_url)
        postgres_server = os.getenv("POSTGRES_SERVER", parsed.hostname)
        postgres_port = os.getenv("POSTGRES_PORT", parsed.port or 5432)
        postgres_user = os.getenv("POSTGRES_USER", parsed.username)
        postgres_password = os.getenv("POSTGRES_PASSWORD", parsed.password)
        target_database = os.getenv("POSTGRES_DB", parsed.path.lstrip('/'))

        print("=" * 60)
        print("ğŸ—„ï¸  å¼€å§‹æ•°æ®åº“åˆå§‹åŒ–...")
        print(f"   æœåŠ¡å™¨: {postgres_server}:{postgres_port}")
        print(f"   æ•°æ®åº“: {target_database}")
        print("=" * 60)

        # 1. å…ˆè¿æ¥åˆ°é»˜è®¤çš„ postgres æ•°æ®åº“
        print("ğŸ”Œ è¿æ¥åˆ°é»˜è®¤æ•°æ®åº“ 'postgres'...")
        conn = psycopg2.connect(
            host=postgres_server,
            port=postgres_port,
            user=postgres_user,
            password=postgres_password,
            database="postgres"
        )
        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
        cur = conn.cursor()

        # 2. æ£€æŸ¥ç›®æ ‡æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        print(f"ğŸ” æ£€æŸ¥æ•°æ®åº“ '{target_database}' æ˜¯å¦å­˜åœ¨...")
        cur.execute("SELECT 1 FROM pg_database WHERE datname=%s", (target_database,))
        exists = cur.fetchone()

        if not exists:
            print(f"ğŸ“¦ åˆ›å»ºæ•°æ®åº“ '{target_database}'...")
            cur.execute(f'CREATE DATABASE "{target_database}"')
            print(f"âœ… æ•°æ®åº“ '{target_database}' åˆ›å»ºæˆåŠŸ")
        else:
            print(f"âœ… æ•°æ®åº“ '{target_database}' å·²å­˜åœ¨")

        cur.close()
        conn.close()

        # 3. ç°åœ¨å¯¼å…¥ SQLAlchemy å¹¶åˆ›å»ºè¡¨
        from app.database import Base, engine
        from sqlalchemy import text

        print("ğŸ“Š åˆ›å»ºæ•°æ®åº“è¡¨...")

        # å…ˆå¯ç”¨ pgvector æ‰©å±•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            with engine.connect() as conn:
                # å°è¯•åˆ›å»º vector æ‰©å±•
                conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector;"))
                conn.commit()
                print("âœ… pgvector æ‰©å±•å·²å¯ç”¨")
        except Exception as e:
            print(f"âš ï¸  è­¦å‘Š: æ— æ³•å¯ç”¨ pgvector æ‰©å±•: {e}")
            print("   å¦‚æœä»£ç ä¸­ä½¿ç”¨äº† Vector ç±»å‹ï¼Œè¡¨åˆ›å»ºå¯èƒ½ä¼šå¤±è´¥")

        Base.metadata.create_all(bind=engine, checkfirst=True)
        print("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")

        # 4. éªŒè¯å…³é”®è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
        conn = psycopg2.connect(
            host=postgres_server,
            port=postgres_port,
            user=postgres_user,
            password=postgres_password,
            database=target_database
        )
        cur = conn.cursor()

        tables_to_check = ['users', 'tasks', 'task_view_records']
        all_exist = True
        for table in tables_to_check:
            cur.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables
                    WHERE table_schema = 'public'
                    AND table_name = %s
                );
            """, (table,))
            exists = cur.fetchone()[0]
            status = "âœ…" if exists else "âŒ"
            print(f"   {status} è¡¨ '{table}': {'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}")
            if not exists:
                all_exist = False

        cur.close()
        conn.close()

        if all_exist:
            print("=" * 60)
            print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ!")
            print("=" * 60)
        else:
            print("âš ï¸  è­¦å‘Š: éƒ¨åˆ†è¡¨æœªåˆ›å»ºæˆåŠŸ")

        return all_exist

    except Exception as e:
        print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

# æ‰§è¡Œæ•°æ®åº“åˆå§‹åŒ–
print("\nğŸš€ æ­£åœ¨å¯åŠ¨åº”ç”¨...")
init_success = init_database()
if not init_success:
    print("âš ï¸  è­¦å‘Š: æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œä½†åº”ç”¨å°†ç»§ç»­å¯åŠ¨")

# =================================================================
# 3. ğŸ“¥ å¯¼å…¥åç«¯åº”ç”¨
# =================================================================
try:
    from app.main import app
    print("âœ… æˆåŠŸå¯¼å…¥ app.main")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    # ç´§æ€¥åˆ›å»ºä¸€ä¸ªä¸´æ—¶ app ç”¨äºæŠ¥é”™
    from fastapi import FastAPI
    app = FastAPI()

# =================================================================
# ğŸ•µï¸â€â™‚ï¸ ç¯å¢ƒè°ƒè¯•æ¥å£ (è®¿é—®è¿™ä¸ªæ¥å£æŸ¥çœ‹é…ç½®çŠ¶æ€)
# =================================================================
@app.get("/api/v1/debug/env-check")
async def debug_env_check():
    """
    è¯Šæ–­ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®åŠ è½½
    """
    return {
        "status": "debug",
        "env_source": "ä» Dockerfile é…ç½®åŠ è½½ï¼ˆæ— éœ€ .env æ–‡ä»¶ï¼‰",
        "critical_vars": {
            "OPENAI_API_KEY": f"âœ… å·²é…ç½® (é•¿åº¦: {len(os.getenv('OPENAI_API_KEY', ''))})" if os.getenv("OPENAI_API_KEY") else "âŒ æœªé…ç½®",
            "LANGCHAIN_API_KEY": f"âœ… å·²é…ç½® (é•¿åº¦: {len(os.getenv('LANGCHAIN_API_KEY', ''))})" if os.getenv("LANGCHAIN_API_KEY") else "âŒ æœªé…ç½®",
            "DEEPSEEK_API_KEY": f"âœ… å·²é…ç½® (é•¿åº¦: {len(os.getenv('DEEPSEEK_API_KEY', ''))})" if os.getenv("DEEPSEEK_API_KEY") else "âŒ æœªé…ç½®",
            "QWEN3_THINKING_API_KEY": f"âœ… å·²é…ç½® (é•¿åº¦: {len(os.getenv('QWEN3_THINKING_API_KEY', ''))})" if os.getenv("QWEN3_THINKING_API_KEY") else "âŒ æœªé…ç½®",
            "DATABASE_URL": f"âœ… {os.getenv('DATABASE_URL', '')[:50]}..." if os.getenv("DATABASE_URL") else "âŒ æœªé…ç½®",
            "REDIS_URL": f"âœ… å·²é…ç½®" if os.getenv("REDIS_URL") else "âŒ æœªé…ç½®",
        },
        "all_env_vars_count": len(os.environ),
        "current_dir": current_dir,
    }

# =================================================================
# 4. ğŸ”¥ å…¨å±€å¼‚å¸¸æ•è·
# =================================================================
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    error_detail = traceback.format_exc()
    print(f"ğŸ”¥ [è¿è¡Œæ—¶é”™è¯¯]: {error_detail}")
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "message": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(exc)}",
            "tips": "è¯·è®¿é—® /api/v1/debug/env-check æ¥å£æŸ¥çœ‹ç¯å¢ƒå˜é‡çŠ¶æ€",
            "timestamp": str(os.times())
        }
    )

# =================================================================
# 5. ğŸ“‚ æŒ‚è½½é™æ€æ–‡ä»¶ (å‰ç«¯æ„å»ºäº§ç‰©)
# =================================================================
# å°è¯•å¤šä¸ªè·¯å¾„æŸ¥æ‰¾å‰ç«¯æ„å»ºæ–‡ä»¶
frontend_paths = [
    os.path.join(current_dir, "backend", "static", "frontend"),  # Docker æ„å»ºåçš„è·¯å¾„
    os.path.join(current_dir, "frontend", "dist"),  # æœ¬åœ°å¼€å‘è·¯å¾„
]

frontend_dist_path = None
for path in frontend_paths:
    if os.path.exists(path):
        frontend_dist_path = path
        print(f"âœ… æ‰¾åˆ°å‰ç«¯æ„å»ºç›®å½•: {frontend_dist_path}")
        break

if not frontend_dist_path:
    print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°å‰ç«¯æ„å»ºç›®å½•ï¼Œå°†åªæä¾› API æœåŠ¡")
    print(f"   æŸ¥æ‰¾è·¯å¾„: {frontend_paths}")
else:
    # æŒ‚è½½å‰ç«¯é™æ€èµ„æº
    assets_dir = os.path.join(frontend_dist_path, "assets")
    if os.path.exists(assets_dir):
        app.mount("/assets", StaticFiles(directory=assets_dir), name="assets")
        print(f"âœ… å·²æŒ‚è½½å‰ç«¯èµ„æºç›®å½•: /assets -> {assets_dir}")

    @app.get("/{full_path:path}")
    async def catch_all(full_path: str):
        # æ’é™¤ API è·¯ç”±ã€é™æ€èµ„æºã€æ–‡æ¡£ç­‰è·¯å¾„
        excluded_prefixes = ("api", "docs", "redoc", "storage", "health", "openapi")
        if full_path.startswith(excluded_prefixes):
            raise HTTPException(status_code=404, detail="Not Found")
        index_file = os.path.join(frontend_dist_path, "index.html")
        if os.path.exists(index_file):
            return FileResponse(index_file)
        raise HTTPException(status_code=404, detail="Frontend not built")

# =================================================================
# 6. ğŸš€ å¯åŠ¨ï¼ˆCelery Worker ä¸ Uvicorn å¹¶è¡Œè¿è¡Œï¼‰
# =================================================================
if __name__ == "__main__":
    import subprocess
    import os
    import threading
    import signal
    import sys
    from pathlib import Path
    import socket

    # ğŸ”§ æ™ºèƒ½é€‰æ‹© Redis é…ç½®ï¼šK8s ç¯å¢ƒç”¨ K8s Redisï¼Œæœ¬åœ°å¼€å‘ç”¨æœ¬åœ° Redis
    k8s_redis_url = "redis://:123myredissecret@redis7.gms.svc.cluster.local:6379/1"
    local_redis_url = "redis://localhost:6379/0"

    # æ£€æµ‹æ˜¯å¦èƒ½è¿æ¥åˆ° K8s Redis
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(1)
        result = sock.connect_ex(('redis7.gms.svc.cluster.local', 6379))
        sock.close()
        use_k8s_redis = (result == 0)
    except Exception:
        use_k8s_redis = False

    # æ ¹æ®ç¯å¢ƒé€‰æ‹© Redis URL
    redis_url = k8s_redis_url if use_k8s_redis else local_redis_url

    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["CELERY_BROKER_URL"] = redis_url
    os.environ["CELERY_RESULT_BACKEND"] = redis_url
    os.environ["REDIS_URL"] = redis_url
    os.environ["CELERY_ENABLED"] = "true"

    print("=" * 60)
    print("ğŸš€ å¯åŠ¨æ¨¡å¼: Uvicorn + Celery Worker (å¹¶è¡Œ)")
    print(f"   ç¯å¢ƒ: {'K8s é›†ç¾¤' if use_k8s_redis else 'æœ¬åœ°å¼€å‘'}")
    print(f"   Celery Broker: {redis_url}")
    print("=" * 60)

    # ç”¨äºè¿½è¸ªå­è¿›ç¨‹
    celery_worker_process = None

    def run_celery_worker():
        """åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œ Celery Worker"""
        global celery_worker_process

        # ä½¿ç”¨ Python -m celery æ–¹å¼å¯åŠ¨ï¼Œç¡®ä¿å‘½ä»¤èƒ½æ‰¾åˆ°
        celery_cmd = [
            sys.executable, "-m", "celery", "-A", "app.tasks.celery_app",
            "worker",
            "--loglevel=info",
            "--concurrency=2",
            "--queues=high_priority,medium_priority,low_priority,default",
            "--max-tasks-per-child=100",
        ]

        print("[Celery Worker] å¯åŠ¨å‘½ä»¤:", " ".join(celery_cmd))
        print("[Celery Worker] å·¥ä½œç›®å½•:", os.getcwd())

        try:
            # ğŸ”‘ å…³é”®ä¿®å¤ï¼šè®¾ç½® PYTHONPATH ç¡®ä¿å­è¿›ç¨‹èƒ½æ‰¾åˆ° app æ¨¡å—
            worker_env = os.environ.copy()
            backend_path = os.path.join(current_dir, "backend")
            worker_env["PYTHONPATH"] = backend_path + ":" + worker_env.get("PYTHONPATH", "")

            # ä½¿ç”¨ Popen è¿è¡Œï¼Œä¸ç­‰å¾…å®Œæˆ
            celery_worker_process = subprocess.Popen(
                celery_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True,
                env=worker_env  # ä¼ é€’ç¯å¢ƒå˜é‡ï¼ˆåŒ…å« PYTHONPATHï¼‰
            )

            print(f"[Celery Worker] PID: {celery_worker_process.pid}")

            # å®æ—¶è¾“å‡ºæ—¥å¿—
            for line in celery_worker_process.stdout:
                print(f"[Celery Worker] {line}", end='')

            # Worker è¿›ç¨‹é€€å‡º
            return_code = celery_worker_process.wait()
            print(f"[Celery Worker] è¿›ç¨‹é€€å‡ºï¼Œè¿”å›ç : {return_code}")

        except FileNotFoundError as e:
            print(f"[Celery Worker] å¯åŠ¨å¤±è´¥ - å‘½ä»¤æœªæ‰¾åˆ°: {e}")
            print(f"[Celery Worker] è¯·ç¡®ä¿ celery åŒ…å·²å®‰è£…: pip install celery redis")
            import traceback
            traceback.print_exc()
        except Exception as e:
            print(f"[Celery Worker] å¯åŠ¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    def signal_handler(signum, frame):
        """å¤„ç†ç»ˆæ­¢ä¿¡å·ï¼Œæ¸…ç†å­è¿›ç¨‹"""
        print(f"\n[ä¸»è¿›ç¨‹] æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨å…³é—­...")
        if celery_worker_process:
            print(f"[ä¸»è¿›ç¨‹] ç»ˆæ­¢ Celery Worker (PID: {celery_worker_process.pid})...")
            celery_worker_process.terminate()
            try:
                celery_worker_process.wait(timeout=10)
            except subprocess.TimeoutExpired:
                celery_worker_process.kill()
        sys.exit(0)

    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)

    # ğŸ”‘ å…³é”®ä¿®å¤ï¼šä½¿ç”¨é daemon çº¿ç¨‹ï¼Œç¡®ä¿ Worker ä¸ä¼šè¢«å›æ”¶
    # daemon=False çº¿ç¨‹ä¼šé˜»æ­¢ç¨‹åºé€€å‡ºï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬éœ€è¦çš„
    celery_thread = threading.Thread(target=run_celery_worker, daemon=False)
    celery_thread.start()

    # ç­‰å¾…ä¸€ä¸‹ï¼Œç¡®ä¿ Worker å¯åŠ¨æˆåŠŸ
    import time
    time.sleep(5)  # å¢åŠ ç­‰å¾…æ—¶é—´åˆ° 5 ç§’

    # æ£€æŸ¥ Worker æ˜¯å¦è¿˜åœ¨è¿è¡Œ
    if celery_worker_process and celery_worker_process.poll() is None:
        print("âœ… Celery Worker å¯åŠ¨æˆåŠŸ")
    else:
        print("âš ï¸  è­¦å‘Š: Celery Worker å¯èƒ½å¯åŠ¨å¤±è´¥ï¼Œä½† Uvicorn å°†ç»§ç»­è¿è¡Œ")
        if celery_worker_process:
            poll_result = celery_worker_process.poll()
            print(f"âš ï¸  Worker è¿›ç¨‹çŠ¶æ€: {poll_result}")

    # å¯åŠ¨ Uvicornï¼ˆä¸»çº¿ç¨‹ï¼Œé˜»å¡è¿è¡Œï¼‰
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ Uvicorn...")
    uvicorn.run(app, host="0.0.0.0", port=8000)