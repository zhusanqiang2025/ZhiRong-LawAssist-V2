# backend/app/services/risk_analysis_service.py
"""
é£é™©è¯„ä¼°æ ¸å¿ƒæœåŠ¡

è´Ÿè´£ï¼š
1. æ–‡æ¡£è§£æï¼ˆä¾èµ– UnifiedDocumentServiceï¼‰
2. é¢„åˆ†æï¼ˆLLM æå–å®ä½“ã€ç”Ÿæˆæ‘˜è¦ï¼‰
3. è§„åˆ™å¼•æ“æ‰«æï¼ˆå†…ç½® + è‡ªå®šä¹‰è§„åˆ™ï¼‰
4. LLM æ·±åº¦åˆ†æ
5. ç”ŸæˆæŠ¥å‘Š
"""

import logging
import uuid
import json
import re
from typing import Dict, List, Optional, Any, Callable
from sqlalchemy.orm import Session
from datetime import datetime

from app.models.risk_analysis import (
    RiskAnalysisSession, RiskItem, RiskAnalysisRule,
    RiskAnalysisStatus, RiskLevel
)
from app.services.unified_document_service import get_unified_document_service
from app.services.risk_analysis.document_preorganization import get_document_preorganization_service

logger = logging.getLogger(__name__)


class RiskAnalysisService:
    """é£é™©è¯„ä¼°æœåŠ¡

    æ ¸å¿ƒæµç¨‹ï¼š
    1. æ–‡æ¡£è§£æï¼ˆä¾èµ– UnifiedDocumentServiceï¼‰
    2. é¢„åˆ†æï¼ˆLLM æå–å®ä½“ã€ç”Ÿæˆæ‘˜è¦ï¼‰
    3. è§„åˆ™å¼•æ“æ‰«æï¼ˆå†…ç½® + è‡ªå®šä¹‰è§„åˆ™ï¼‰
    4. LLM æ·±åº¦åˆ†æ
    5. ç”ŸæˆæŠ¥å‘Š
    """

    def __init__(self, db: Session):
        self.db = db
        self.document_service = get_unified_document_service()

    def create_session(
        self,
        user_id: int,
        scene_type: str,
        user_description: Optional[str] = None,
        document_ids: Optional[List[str]] = None
    ) -> RiskAnalysisSession:
        """åˆ›å»ºæ–°çš„é£é™©åˆ†æä¼šè¯"""
        session = RiskAnalysisSession(
            session_id=str(uuid.uuid4()),
            user_id=user_id,
            scene_type=scene_type,
            user_description=user_description,
            document_ids=document_ids,
            status=RiskAnalysisStatus.PENDING.value
        )
        self.db.add(session)
        self.db.commit()
        self.db.refresh(session)
        logger.info(f"åˆ›å»ºé£é™©åˆ†æä¼šè¯: {session.session_id}, åœºæ™¯: {scene_type}")
        return session

    async def analyze_documents(
        self,
        session_id: str,
        document_paths: List[str],
        scene_type: str,
        user_description: Optional[str] = None,
        enable_custom_rules: bool = False,
        user_id: Optional[int] = None,
        progress_callback: Optional[Callable] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œé£é™©åˆ†æ

        Args:
            session_id: ä¼šè¯ ID
            document_paths: æ–‡æ¡£è·¯å¾„åˆ—è¡¨
            scene_type: åˆ†æåœºæ™¯
            user_description: ç”¨æˆ·æè¿°
            enable_custom_rules: æ˜¯å¦å¯ç”¨è‡ªå®šä¹‰è§„åˆ™
            user_id: ç”¨æˆ· ID
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # 1. è·å–ä¼šè¯
        session = self.db.query(RiskAnalysisSession).filter(
            RiskAnalysisSession.session_id == session_id
        ).first()

        if not session:
            raise ValueError(f"ä¼šè¯ {session_id} ä¸å­˜åœ¨")

        try:
            # 2. æ–‡æ¡£è§£æé˜¶æ®µ
            logger.info(f"å¼€å§‹æ–‡æ¡£è§£æï¼Œå…± {len(document_paths)} ä¸ªæ–‡ä»¶")
            await self._update_progress(session, "parsing", 0.1, "æ­£åœ¨è§£ææ–‡æ¡£...", progress_callback)

            # æ£€æŸ¥æ˜¯å¦æœ‰å·²å¤„ç†çš„æ–‡æ¡£ç»“æœï¼ˆä»ä¸Šä¼ é˜¶æ®µä¿å­˜çš„ï¼‰
            if hasattr(session, 'document_processing_results') and session.document_processing_results:
                logger.info(f"[DOC_PREORG] å‘ç°å·²å¤„ç†çš„æ–‡æ¡£ç»“æœï¼Œå…± {len(session.document_processing_results)} ä¸ªæ–‡ä»¶")
                # ä½¿ç”¨å·²å¤„ç†çš„æ–‡æ¡£ç»“æœ
                parsed_docs = []
                for filename, proc_result in session.document_processing_results.items():
                    # é‡æ–°åŠ è½½æ–‡æ¡£ä»¥è·å–å®Œæ•´ç»“æ„åŒ–æ•°æ®
                    file_path = proc_result.get("file_path")
                    if file_path:
                        try:
                            result = self.document_service.process_document_structured(file_path)
                            parsed_docs.append({
                                "path": file_path,
                                "content": result.content,
                                "metadata": result.metadata,
                                "structure": {
                                    "paragraphs": result.paragraphs,
                                    "tables": result.tables,
                                    "parties": result.parties
                                }
                            })
                            logger.info(f"[DOC_PREORG] ä»ç¼“å­˜åŠ è½½æ–‡æ¡£: {filename}")
                        except Exception as e:
                            logger.warning(f"[DOC_PREORG] é‡æ–°åŠ è½½æ–‡æ¡£å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")
                            continue
            else:
                # åŸæœ‰é€»è¾‘ï¼šè§£ææ–‡æ¡£
                parsed_docs = []
                for doc_path in document_paths:
                    try:
                        result = self.document_service.process_document_structured(doc_path)
                        parsed_docs.append({
                            "path": doc_path,
                            "content": result.content,
                            "metadata": result.metadata,
                            "structure": {
                                "paragraphs": result.paragraphs,
                                "tables": result.tables,
                                "parties": result.parties
                            }
                        })
                    except Exception as e:
                        logger.warning(f"æ–‡æ¡£è§£æå¤±è´¥: {doc_path}, é”™è¯¯: {str(e)}")
                        # ç»§ç»­å¤„ç†å…¶ä»–æ–‡æ¡£
                        continue

            if not parsed_docs:
                raise ValueError("æ²¡æœ‰æˆåŠŸè§£æä»»ä½•æ–‡æ¡£")

            # 2.5 æ–‡æ¡£é¢„æ•´ç†é˜¶æ®µï¼ˆèŠ‚ç‚¹2ï¼šä¸“ä¸šåŠ©ç†èŠ‚ç‚¹ï¼‰
            logger.info(f"[DOC_PREORG] å¼€å§‹æ–‡æ¡£é¢„æ•´ç†")
            await self._update_progress(session, "preorganizing", 0.2, "æ­£åœ¨è¿›è¡Œæ–‡æ¡£é¢„æ•´ç†...", progress_callback)

            try:
                # è·å–LLMå®ä¾‹
                from app.core.llm_config import get_deepseek_llm
                llm = get_deepseek_llm()

                # è·å–DocumentPreorganizationService
                preorg_service = get_document_preorganization_service(llm)

                # å°†parsed_docsè½¬æ¢ä¸ºStructuredDocumentResultæ ¼å¼
                from app.services.unified_document_service import StructuredDocumentResult, DocumentProcessingStatus
                structured_docs = []
                for doc in parsed_docs:
                    # æ„å»ºStructuredDocumentResultå¯¹è±¡
                    structured_doc = StructuredDocumentResult(
                        status=DocumentProcessingStatus.SUCCESS,
                        content=doc["content"],
                        metadata=doc["metadata"],
                        paragraphs=doc["structure"].get("paragraphs", []),
                        tables=doc["structure"].get("tables", []),
                        headings=[],  # å¯é€‰ï¼Œå¦‚æœä¸éœ€è¦å¯ä»¥ç•™ç©º
                        parties=doc["structure"].get("parties", []),
                        signatures=[],  # å¯é€‰
                        processing_method="v1_analysis",
                        from_cache=False
                    )
                    structured_docs.append(structured_doc)

                # æ‰§è¡Œé¢„æ•´ç†
                preorganized = await preorg_service.preorganize(
                    documents=structured_docs,
                    user_context=user_description
                )

                logger.info(f"[DOC_PREORG] é¢„æ•´ç†å®Œæˆ:")
                logger.info(f"[DOC_PREORG] - æ–‡æ¡£åˆ†ç±»: {preorganized.document_classification}")
                logger.info(f"[DOC_PREORG] - è´¨é‡è¯„åˆ†: {len(preorganized.quality_scores)} ä¸ªæ–‡æ¡£")
                logger.info(f"[DOC_PREORG] - æ™ºèƒ½æ‘˜è¦: {len(preorganized.document_summaries)} ä¸ªæ–‡æ¡£")
                logger.info(f"[DOC_PREORG] - æ–‡æ¡£å…³ç³»: {len(preorganized.document_relationships)} ä¸ªå…³ç³»")
                if preorganized.duplicates:
                    logger.info(f"[DOC_PREORG] - é‡å¤æ–‡æ¡£: {len(preorganized.duplicates)} å¯¹")

                # ä¿å­˜é¢„æ•´ç†ç»“æœåˆ°ä¼šè¯
                session.document_preorganization = {
                    "classification": preorganized.document_classification,
                    "quality_scores": preorganized.quality_scores,
                    "summaries": [s.dict() for s in preorganized.document_summaries],
                    "relationships": [r.dict() for r in preorganized.document_relationships],
                    "duplicates": preorganized.duplicates or [],
                    "ranked_docs": preorganized.ranked_documents,
                    "cross_doc_info": preorganized.cross_doc_info or {}
                }
                self.db.commit()

            except Exception as e:
                logger.warning(f"[DOC_PREORG] æ–‡æ¡£é¢„æ•´ç†å¤±è´¥ï¼Œå°†è·³è¿‡æ­¤æ­¥éª¤: {str(e)}", exc_info=True)
                # é¢„æ•´ç†å¤±è´¥ä¸å½±å“åç»­æµç¨‹
                session.document_preorganization = {"error": str(e)}
                self.db.commit()

            # 3. é¢„åˆ†æé˜¶æ®µï¼ˆLLM æ‘˜è¦å’Œå®ä½“æå–ï¼‰
            logger.info("å¼€å§‹é¢„åˆ†æé˜¶æ®µ")
            await self._update_progress(session, "analyzing", 0.3, "æ­£åœ¨è¿›è¡Œé¢„åˆ†æ...", progress_callback)

            pre_analysis = await self._preanalyze_documents(
                parsed_docs, scene_type, user_description
            )

            # 4. è§„åˆ™å¼•æ“æ‰«æ
            logger.info("å¼€å§‹è§„åˆ™å¼•æ“æ‰«æ")
            await self._update_progress(session, "analyzing", 0.5, "æ­£åœ¨åº”ç”¨è§„åˆ™å¼•æ“...", progress_callback)

            rule_results = await self._apply_rule_engine(
                parsed_docs, scene_type, enable_custom_rules, user_id
            )

            # 5. LLM æ·±åº¦åˆ†æ
            logger.info("å¼€å§‹ LLM æ·±åº¦åˆ†æ")
            await self._update_progress(session, "analyzing", 0.7, "æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ...", progress_callback)

            llm_results = await self._deep_analysis_with_llm(
                parsed_docs, pre_analysis, rule_results, scene_type
            )

            # 6. æ•´åˆç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š
            logger.info("ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
            await self._update_progress(session, "analyzing", 0.9, "æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...", progress_callback)

            final_result = await self._generate_final_report(
                session, pre_analysis, rule_results, llm_results
            )

            # 7. æ›´æ–°ä¼šè¯çŠ¶æ€
            session.status = RiskAnalysisStatus.COMPLETED.value
            session.completed_at = datetime.utcnow()
            session.summary = final_result["summary"]
            session.risk_distribution = final_result["distribution"]
            session.total_confidence = final_result["confidence"]
            session.report_md = final_result["report_md"]
            session.report_json = final_result["report_json"]
            self.db.commit()

            await self._update_progress(session, "completed", 1.0, "åˆ†æå®Œæˆ", progress_callback)

            logger.info(f"é£é™©åˆ†æå®Œæˆ: {session_id}, å…±å‘ç° {len(final_result['report_json']['risks'])} ä¸ªé£é™©ç‚¹")
            return final_result

        except Exception as e:
            logger.error(f"é£é™©åˆ†æå¤±è´¥: {str(e)}", exc_info=True)
            session.status = RiskAnalysisStatus.FAILED.value
            self.db.commit()
            raise

    async def _preanalyze_documents(
        self,
        parsed_docs: List[Dict],
        scene_type: str,
        user_description: Optional[str]
    ) -> Dict[str, Any]:
        """é¢„åˆ†æï¼šLLM æå–æ‘˜è¦å’Œå®ä½“"""
        try:
            from app.core.llm_config import get_deepseek_llm
            llm = get_deepseek_llm()

            combined_content = "\n\n".join([doc["content"] for doc in parsed_docs])

            # é™åˆ¶å†…å®¹é•¿åº¦
            content_preview = combined_content[:10000]

            prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„æ³•å¾‹æ–‡æ¡£åˆ†æå¸ˆã€‚è¯·å¯¹ä»¥ä¸‹æ–‡æ¡£è¿›è¡Œé¢„åˆ†æï¼š

åˆ†æåœºæ™¯ï¼š{scene_type}
ç”¨æˆ·æè¿°ï¼š{user_description or 'æ— '}

æ–‡æ¡£å†…å®¹ï¼š
{content_preview}

è¯·è¾“å‡º JSON æ ¼å¼ï¼ˆä¸è¦åŒ…å«å…¶ä»–å†…å®¹ï¼‰ï¼š
{{
    "summary": "æ–‡æ¡£æ‘˜è¦ï¼ˆ100å­—ä»¥å†…ï¼‰",
    "entities": ["å®ä½“1", "å®ä½“2"],
    "key_terms": ["å…³é”®æ¡æ¬¾1", "å…³é”®æ¡æ¬¾2"],
    "document_type": "æ–‡æ¡£ç±»å‹"
}}
"""

            response = await llm.ainvoke(prompt)

            # å°è¯•è§£æ JSON
            try:
                # æ¸…ç†å“åº”ä¸­çš„ markdown ä»£ç å—æ ‡è®°
                clean_response = response.content.strip()
                if clean_response.startswith("```json"):
                    clean_response = clean_response[7:]
                if clean_response.startswith("```"):
                    clean_response = clean_response[3:]
                if clean_response.endswith("```"):
                    clean_response = clean_response[:-3]
                clean_response = clean_response.strip()

                return json.loads(clean_response)
            except json.JSONDecodeError:
                logger.warning(f"LLM è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆ JSON: {response.content[:200]}")
                return {
                    "summary": "æ–‡æ¡£é¢„åˆ†æå®Œæˆ",
                    "entities": [],
                    "key_terms": [],
                    "document_type": scene_type
                }

        except Exception as e:
            logger.error(f"é¢„åˆ†æå¤±è´¥: {str(e)}")
            return {
                "summary": "é¢„åˆ†æå¤±è´¥",
                "entities": [],
                "key_terms": [],
                "document_type": scene_type
            }

    async def _apply_rule_engine(
        self,
        parsed_docs: List[Dict],
        scene_type: str,
        enable_custom_rules: bool,
        user_id: Optional[int]
    ) -> List[Dict]:
        """åº”ç”¨è§„åˆ™å¼•æ“è¿›è¡Œé£é™©æ‰«æ"""
        # æŸ¥è¯¢é€‚ç”¨çš„è§„åˆ™
        query = self.db.query(RiskAnalysisRule).filter(
            RiskAnalysisRule.scene_type == scene_type,
            RiskAnalysisRule.is_active == True
        )

        if enable_custom_rules and user_id:
            query = query.filter(
                (RiskAnalysisRule.rule_category == "universal") |
                (RiskAnalysisRule.creator_id == user_id)
            )
        else:
            query = query.filter(RiskAnalysisRule.rule_category == "universal")

        rules = query.all()
        logger.info(f"åº”ç”¨ {len(rules)} æ¡è§„åˆ™è¿›è¡Œæ‰«æ")

        rule_results = []
        for doc in parsed_docs:
            content = doc["content"]
            for rule in rules:
                # å…³é”®è¯åŒ¹é…
                if rule.keywords:
                    for keyword in rule.keywords:
                        if keyword in content:
                            rule_results.append({
                                "rule_id": rule.id,
                                "rule_name": rule.name,
                                "matched_keyword": keyword,
                                "risk_level": rule.default_risk_level or "medium",
                                "source": "rule_engine",
                                "risk_type": rule.risk_type
                            })

                # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
                if rule.pattern:
                    try:
                        if re.search(rule.pattern, content):
                            rule_results.append({
                                "rule_id": rule.id,
                                "rule_name": rule.name,
                                "matched_pattern": rule.pattern,
                                "risk_level": rule.default_risk_level or "medium",
                                "source": "rule_engine",
                                "risk_type": rule.risk_type
                            })
                    except re.error:
                        logger.warning(f"è§„åˆ™ {rule.name} çš„æ­£åˆ™è¡¨è¾¾å¼æ— æ•ˆ: {rule.pattern}")

        logger.info(f"è§„åˆ™å¼•æ“æ£€æµ‹åˆ° {len(rule_results)} ä¸ªé£é™©ç‚¹")
        return rule_results

    async def _deep_analysis_with_llm(
        self,
        parsed_docs: List[Dict],
        pre_analysis: Dict,
        rule_results: List[Dict],
        scene_type: str
    ) -> List[Dict]:
        """LLM æ·±åº¦åˆ†æ"""
        try:
            from app.core.llm_config import get_deepseek_llm
            llm = get_deepseek_llm()

            combined_content = "\n\n".join([doc["content"] for doc in parsed_docs])
            content_preview = combined_content[:8000]

            # æ„å»ºè§„åˆ™ç»“æœæ‘˜è¦
            rule_summary = "\n".join([
                f"- {rr['rule_name']}: {rr.get('matched_keyword', rr.get('matched_pattern', ''))}"
                for rr in rule_results[:10]
            ])

            prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ä¸­å›½æ³•å¾‹é¡¾é—®ã€‚è¯·è¿›è¡Œæ·±åº¦é£é™©åˆ†æï¼š

åˆ†æåœºæ™¯ï¼š{scene_type}
æ–‡æ¡£æ‘˜è¦ï¼š{pre_analysis.get('summary', '')}
è§„åˆ™å¼•æ“å·²æ£€æµ‹é£é™©ï¼š
{rule_summary}

æ–‡æ¡£å†…å®¹ï¼š
{content_preview}

è¯·è¯†åˆ«æ‰€æœ‰æ½œåœ¨é£é™©ï¼ˆåŒ…æ‹¬è§„åˆ™å¼•æ“æœªæ£€æµ‹åˆ°çš„ï¼‰ï¼Œè¾“å‡ºçº¯ JSON æ ¼å¼ï¼ˆä¸è¦åŒ…å«å…¶ä»–å†…å®¹ï¼‰ï¼š
{{
    "risks": [
        {{
            "title": "é£é™©æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "risk_level": "high/medium/low",
            "confidence": 0.85,
            "reasons": ["ç†ç”±1", "ç†ç”±2"],
            "suggestions": ["å»ºè®®1", "å»ºè®®2"]
        }}
    ]
}}

æ³¨æ„ï¼š
1. risk_level åªèƒ½æ˜¯ high, medium, low ä¹‹ä¸€
2. confidence æ˜¯ 0 åˆ° 1 ä¹‹é—´çš„æ•°å­—
3. å¦‚æœæ²¡æœ‰å‘ç°é£é™©ï¼Œè¿”å›ç©ºçš„ risks æ•°ç»„
"""

            response = await llm.ainvoke(prompt)

            # è§£æ JSON
            try:
                clean_response = response.content.strip()
                if clean_response.startswith("```json"):
                    clean_response = clean_response[7:]
                if clean_response.startswith("```"):
                    clean_response = clean_response[3:]
                if clean_response.endswith("```"):
                    clean_response = clean_response[:-3]
                clean_response = clean_response.strip()

                result = json.loads(clean_response)
                risks = result.get("risks", [])

                # è¿‡æ»¤å’ŒéªŒè¯é£é™©é¡¹
                valid_risks = []
                for risk in risks:
                    if isinstance(risk, dict) and all(k in risk for k in ["title", "description", "risk_level"]):
                        # ç¡®ä¿é£é™©ç­‰çº§æœ‰æ•ˆ
                        if risk["risk_level"] not in ["high", "medium", "low"]:
                            risk["risk_level"] = "medium"
                        # ç¡®ä¿ç½®ä¿¡åº¦æœ‰æ•ˆ
                        if "confidence" not in risk or not isinstance(risk["confidence"], (int, float)):
                            risk["confidence"] = 0.7
                        # ç¡®ä¿ reasons å’Œ suggestions å­˜åœ¨
                        if "reasons" not in risk or not isinstance(risk["reasons"], list):
                            risk["reasons"] = []
                        if "suggestions" not in risk or not isinstance(risk["suggestions"], list):
                            risk["suggestions"] = []

                        valid_risks.append(risk)

                logger.info(f"LLM æ·±åº¦åˆ†æå‘ç° {len(valid_risks)} ä¸ªé£é™©ç‚¹")
                return valid_risks

            except (json.JSONDecodeError, KeyError) as e:
                logger.warning(f"LLM è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆ JSON: {str(e)}, å“åº”: {response[:200]}")
                return []

        except Exception as e:
            logger.error(f"LLM æ·±åº¦åˆ†æå¤±è´¥: {str(e)}")
            return []

    async def _generate_final_report(
        self,
        session: RiskAnalysisSession,
        pre_analysis: Dict,
        rule_results: List[Dict],
        llm_results: List[Dict]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        # åˆå¹¶è§„åˆ™å’Œ LLM ç»“æœ
        all_risks = []

        # è§„åˆ™å¼•æ“ç»“æœ
        for rr in rule_results:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç±»ä¼¼é£é™©ï¼ˆé¿å…é‡å¤ï¼‰
            is_duplicate = any(
                r["title"] == rr["rule_name"] and r["source_type"] == "llm"
                for r in all_risks
            )
            if not is_duplicate:
                all_risks.append({
                    "title": rr["rule_name"],
                    "description": f"æ£€æµ‹åˆ°å…³é”®è¯ï¼š{rr.get('matched_keyword', rr.get('matched_pattern', ''))}",
                    "risk_level": rr["risk_level"],
                    "confidence": 0.9,  # è§„åˆ™åŒ¹é…ç½®ä¿¡åº¦è¾ƒé«˜
                    "reasons": ["è§„åˆ™å¼•æ“æ£€æµ‹"],
                    "suggestions": ["å»ºè®®ä»”ç»†å®¡æŸ¥ç›¸å…³æ¡æ¬¾"],
                    "source_type": "rule",
                    "source_rules": [rr["rule_id"]]
                })

        # LLM ç»“æœ
        for lr in llm_results:
            all_risks.append({
                "title": lr["title"],
                "description": lr["description"],
                "risk_level": lr["risk_level"],
                "confidence": lr["confidence"],
                "reasons": lr["reasons"],
                "suggestions": lr["suggestions"],
                "source_type": "llm",
                "source_rules": None
            })

        # ä¿å­˜é£é™©é¡¹åˆ°æ•°æ®åº“
        for risk_data in all_risks:
            risk_item = RiskItem(
                session_id=session.id,
                title=risk_data["title"],
                description=risk_data["description"],
                risk_level=risk_data["risk_level"],
                confidence=risk_data["confidence"],
                reasons=risk_data["reasons"],
                suggestions=risk_data["suggestions"],
                source_type=risk_data["source_type"],
                source_rules=risk_data.get("source_rules")
            )
            self.db.add(risk_item)

        self.db.commit()

        # è®¡ç®—é£é™©åˆ†å¸ƒ
        distribution = {"high": 0, "medium": 0, "low": 0}
        total_confidence = 0
        for risk in all_risks:
            level = risk["risk_level"]
            if level in distribution:
                distribution[level] += 1
            total_confidence += risk["confidence"]

        avg_confidence = total_confidence / len(all_risks) if all_risks else 0

        # ç”Ÿæˆ Markdown æŠ¥å‘Š
        report_md = self._generate_markdown_report(all_risks, distribution, pre_analysis)

        return {
            "summary": f"å‘ç° {len(all_risks)} ä¸ªé£é™©ç‚¹",
            "distribution": distribution,
            "confidence": avg_confidence,
            "report_md": report_md,
            "report_json": {"risks": all_risks}
        }

    def _generate_markdown_report(
        self,
        risks: List[Dict],
        distribution: Dict[str, int],
        pre_analysis: Dict
    ) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼æŠ¥å‘Š"""
        md_lines = [
            "# é£é™©è¯„ä¼°æŠ¥å‘Š",
            "",
            "## æ–‡æ¡£æ‘˜è¦",
            pre_analysis.get("summary", ""),
            "",
            "## é£é™©åˆ†å¸ƒ",
            f"- é«˜é£é™©ï¼š{distribution.get('high', 0)} ä¸ª",
            f"- ä¸­é£é™©ï¼š{distribution.get('medium', 0)} ä¸ª",
            f"- ä½é£é™©ï¼š{distribution.get('low', 0)} ä¸ª",
            "",
            "## è¯¦ç»†é£é™©æ¸…å•",
            ""
        ]

        for i, risk in enumerate(risks, 1):
            level_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(risk["risk_level"], "âšª")
            md_lines.extend([
                f"### {level_emoji} {i}. {risk['title']}",
                "",
                f"**æè¿°ï¼š** {risk['description']}",
                f"**é£é™©ç­‰çº§ï¼š** {risk['risk_level'].upper()}",
                f"**ç½®ä¿¡åº¦ï¼š** {risk['confidence']:.1%}",
                f"**æ¥æºï¼š** {'è§„åˆ™å¼•æ“' if risk['source_type'] == 'rule' else 'AI åˆ†æ'}",
                "",
                "**ç†ç”±ï¼š**"
            ])
            for reason in risk.get("reasons", []):
                md_lines.append(f"- {reason}")

            md_lines.extend([
                "",
                "**å»ºè®®ï¼š**"
            ])
            for suggestion in risk.get("suggestions", []):
                md_lines.append(f"- {suggestion}")
            md_lines.append("")

        md_lines.extend([
            "---",
            "",
            "**å…è´£å£°æ˜ï¼š** æœ¬è¯„ä¼°ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šå¾‹å¸ˆæ„è§ã€‚"
        ])

        return "\n".join(md_lines)

    async def _update_progress(
        self,
        session: RiskAnalysisSession,
        status: str,
        progress: float,
        message: str,
        callback: Optional[Callable]
    ):
        """æ›´æ–°è¿›åº¦å¹¶é€šçŸ¥"""
        session.status = status
        self.db.commit()

        if callback:
            await callback({
                "session_id": session.session_id,
                "status": status,
                "progress": progress,
                "message": message
            })

    def get_session_by_id(self, session_id: str, user_id: int) -> Optional[RiskAnalysisSession]:
        """æ ¹æ® session_id å’Œ user_id è·å–ä¼šè¯"""
        return self.db.query(RiskAnalysisSession).filter(
            RiskAnalysisSession.session_id == session_id,
            RiskAnalysisSession.user_id == user_id
        ).first()

    def get_session_with_items(self, session_id: str, user_id: int) -> Optional[RiskAnalysisSession]:
        """è·å–ä¼šè¯åŠå…¶é£é™©é¡¹"""
        return self.db.query(RiskAnalysisSession).filter(
            RiskAnalysisSession.session_id == session_id,
            RiskAnalysisSession.user_id == user_id
        ).first()


# ä¾¿æ·å‡½æ•°
def get_risk_analysis_service(db: Session) -> RiskAnalysisService:
    """è·å–é£é™©è¯„ä¼°æœåŠ¡å®ä¾‹"""
    return RiskAnalysisService(db)
