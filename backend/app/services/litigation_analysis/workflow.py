# backend/app/services/litigation_analysis/workflow.py
# Part 1: Imports, State, and Pre-processing Nodes
"""
æ¡ˆä»¶åˆ†æå·¥ä½œæµ - LangGraph ç¼–æ’ (é‡æ„ç‰ˆ - é€‚é…ç»Ÿä¸€é¢„æ•´ç†)

æ ¸å¿ƒæ›´æ–°ï¼š
1. ç»Ÿä¸€è°ƒç”¨ EnhancedCasePreorganizationServiceï¼Œç§»é™¤åŸºç¡€ç‰ˆåˆ†æ”¯ã€‚
2. æ•°æ®æµè½¬é€‚é…å‰ç«¯ 'äº¤æ˜“å…¨æ™¯' ç»„ä»¶ç»“æ„ï¼Œä¿®å¤å±•ç¤ºé—®é¢˜ã€‚
3. å¼ºåŒ– WebSocket è¿›åº¦æ¨é€å’Œé”™è¯¯å¤„ç†ã€‚
"""

import logging
import json
import asyncio
from datetime import datetime
from typing import Dict, Any, Optional, List, TypedDict, Literal
from dataclasses import asdict

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from app.services.unified_document_service import UnifiedDocumentService
# ä½¿ç”¨ç»Ÿä¸€çš„å¢å¼ºç‰ˆæœåŠ¡
from app.services.litigation_analysis.enhanced_case_preorganization import (
    get_enhanced_case_preorganization_service
)
from app.services.litigation_analysis.case_rule_assembler import CaseRuleAssembler
from app.services.litigation_analysis.evidence_analyzer import EvidenceAnalyzer
from app.services.litigation_analysis.timeline_generator import TimelineGenerator
from app.services.litigation_analysis.strategy_generator import StrategyGenerator
from app.services.litigation_analysis.multi_model_analyzer import MultiModelAnalyzer
from app.services.litigation_analysis.report_generator import ReportGenerator

logger = logging.getLogger(__name__)


class LitigationAnalysisState(TypedDict):
    """æ¡ˆä»¶åˆ†æçŠ¶æ€"""
    # ============ è¾“å…¥æ•°æ® ============
    session_id: str
    user_input: Optional[str]
    document_paths: List[str]
    case_package_id: str
    
    # ä¸šåŠ¡å‚æ•°
    case_type: str          
    case_position: Optional[str]     # é˜¶æ®µ1æ—¶å¯èƒ½ä¸º None
    analysis_scenario: Optional[str] # é˜¶æ®µ1æ—¶å¯èƒ½ä¸º None
    
    # é…ç½®
    analysis_mode: str      
    selected_model: Optional[str]

    # ============ å¤„ç†ç»“æœ ============
    raw_documents: Optional[List[Any]]
    
    # ç»Ÿä¸€åçš„å¢å¼ºæ•°æ®ç»“æ„ï¼ŒåŒ…å« document_summaries, enhanced_analysis_compatible ç­‰
    preorganized_case: Optional[Dict[str, Any]] 

    assembled_rules: Optional[List[str]]        
    timeline: Optional[Dict[str, Any]]          
    evidence_analysis: Optional[Dict[str, Any]] 
    model_results: Optional[Dict[str, Any]]     
    strategies: Optional[List[Dict[str, Any]]]  
    draft_documents: Optional[List[Dict[str, Any]]] 
    final_report: Optional[str]                 
    report_json: Optional[Dict[str, Any]]       

    # ============ çŠ¶æ€æ§åˆ¶ ============
    status: str
    error: Optional[str]


# ==================== è¾…åŠ©å‡½æ•° ====================

async def send_ws_progress(session_id: str, node: str, status: str, message: str = "", progress: float = 0.0):
    """å‘é€ WebSocket è¿›åº¦ï¼ˆå¢å¼ºè¯Šæ–­ç‰ˆï¼‰"""
    try:
        from app.api.websocket import manager

        # æ£€æŸ¥è¿æ¥æ˜¯å¦å­˜åœ¨ï¼ˆé¿å…Broken Pipeï¼‰
        if not manager.is_connected(session_id):
            logger.warning(f"[{session_id}] âš ï¸ WebSocket æœªè¿æ¥ï¼Œæ— æ³•å‘é€è¿›åº¦: node={node}, status={status}, message={message}")
            return

        logger.debug(f"[{session_id}] å‘é€è¿›åº¦: node={node}, status={status}, progress={progress}, message={message}")
        await manager.send_progress(session_id, {
            "type": "node_progress",
            "node": node,
            "status": status,
            "message": message,
            "progress": progress
        })
    except Exception as e:
        logger.error(f"[{session_id}] å‘é€è¿›åº¦å¤±è´¥: node={node}, error={e}")
        # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
        pass

def check_error_status(state: LitigationAnalysisState) -> Literal["continue", "end"]:
    """ç†”æ–­æœºåˆ¶"""
    if state.get("error"):
        logger.warning(f"[{state.get('session_id')}] å·¥ä½œæµç†”æ–­: {state['error']}")
        return "end"
    return "continue"


# ==================== å·¥ä½œæµèŠ‚ç‚¹ ====================

async def process_documents_node(state: LitigationAnalysisState) -> Dict[str, Any]:
    """èŠ‚ç‚¹1: æ–‡æ¡£å¤„ç†"""
    if state.get("raw_documents"):
        return {"status": "documents_ready"}

    logger.info(f"[{state['session_id']}] å¼€å§‹å¤„ç†æ–‡æ¡£")
    await send_ws_progress(state['session_id'], "process_documents", "processing", "æ­£åœ¨è§£ææ–‡æ¡£å†…å®¹...", 0.1)
    
    try:
        doc_service = UnifiedDocumentService()
        results = await doc_service.batch_process_async(
            state["document_paths"],
            extract_content=True,
            extract_metadata=True
        )
        successful_docs = [r for r in results if r.status == 'success']
        
        if not successful_docs:
            raise ValueError("æ²¡æœ‰æˆåŠŸè§£æçš„æ–‡æ¡£ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")

        return {
            "raw_documents": successful_docs,
            "status": "documents_processed"
        }
    except Exception as e:
        return {"error": f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}", "status": "failed"}


async def preorganize_case_node(state: LitigationAnalysisState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹2: ç»Ÿä¸€é¢„æ•´ç† (Unified Preorganization)
    
    æ— è®ºæ˜¯å¦é€‰æ‹©äº†è§’è‰²ï¼Œéƒ½è°ƒç”¨ Enhanced Serviceã€‚
    æœªé€‰è§’è‰²æ—¶ï¼Œé»˜è®¤ä¸º 'ä¸­ç«‹' è§†è§’ï¼Œç”Ÿæˆæ¡ˆä»¶å…¨æ™¯ã€‚
    """
    session_id = state['session_id']
    
    # 1. æ£€æŸ¥å¤ç”¨ (å¦‚æœç”¨æˆ·å·²ç»ç¡®è®¤è¿‡å¹¶é‡æ–°è¿›å…¥)
    if state.get("preorganized_case") and state.get("preorganized_case", {}).get("is_confirmed"):
        logger.info(f"[{session_id}] å¤ç”¨å·²ç¡®è®¤çš„é¢„æ•´ç†æ•°æ®")
        return {"status": "preorganization_ready"}

    # 2. å‡†å¤‡å‚æ•°
    case_position = state.get('case_position')
    analysis_scenario = state.get('analysis_scenario')
    
    logger.info(f"[{session_id}] å¼€å§‹é¢„æ•´ç† | è§†è§’: {case_position or 'è‡ªåŠ¨è¯†åˆ«(ä¸­ç«‹)'}")

    try:
        from app.core.llm_config import get_qwen_llm
        llm = get_qwen_llm()

        # éªŒè¯ LLM æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
        if llm is None:
            error_msg = "LLM æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼šæœªé…ç½®æœ‰æ•ˆçš„ API Key"
            logger.error(f"[{session_id}] {error_msg}")
            await send_ws_progress(session_id, "preorganize", "failed", error_msg, 0)
            return {"error": error_msg, "status": "failed"}

        service = get_enhanced_case_preorganization_service(llm)
        logger.info(f"[{session_id}] LLM æœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼Œå‡†å¤‡é¢„æ•´ç†")

        # å®šä¹‰å›è°ƒ
        async def progress_callback(step: str, progress: float, message: str):
            await send_ws_progress(session_id, "preorganize", "processing", message, progress)

        # 3. æ‰§è¡Œåˆ†æ (ç»Ÿä¸€å…¥å£)
        preorganized_result = await service.preorganize_enhanced(
            documents=state["raw_documents"],
            case_type=state["case_type"],
            case_position=case_position, # å¦‚æœä¸ºNoneï¼ŒServiceå†…éƒ¨å¤„ç†ä¸ºä¸­ç«‹è§†è§’
            analysis_scenario=analysis_scenario,
            user_context=state.get("user_input"),
            progress_callback=progress_callback
        )

        # 4. æ•°æ®æ¨é€ (å…³é”®ï¼šå¯¹é½å‰ç«¯ç»„ä»¶)
        # å‰ç«¯ç»„ä»¶ RiskAnalysisPageV2 å¤ç”¨äº†é£é™©è¯„ä¼°çš„ EnhancedAnalysisDisplay
        # æ‰€ä»¥æˆ‘ä»¬éœ€è¦æ„é€  compatible_data æ”¾å…¥ enhanced_analysis å­—æ®µ
        try:
            from app.api.websocket import manager
            
            # æå–å…¼å®¹æ•°æ® (transaction_summary, parties, timeline)
            compatible_data = preorganized_result.get("enhanced_analysis_compatible", {})
            
            # æ„é€  WebSocket Payload
            payload = {
                "type": "preorganization_completed",
                "has_result": True,
                "can_proceed": True,
                
                # åŸºç¡€åˆ—è¡¨æ•°æ® (ç”¨äºæ–‡ä»¶åˆ—è¡¨å±•ç¤º)
                "preorganized_data": {
                    "document_summaries": preorganized_result.get("document_summaries", {}),
                    "case_type": state["case_type"]
                },
                
                # æ ¸å¿ƒï¼šæ”¾å…¥ enhanced_analysis å­—æ®µï¼Œè¿™æ˜¯å‰ç«¯ç»„ä»¶çš„æ•°æ®æº
                "enhanced_analysis": compatible_data, 
                
                # å†—ä½™ä¸€ä»½åˆ° enhanced_data ä»¥é˜²ä¸‡ä¸€
                "enhanced_data": compatible_data 
            }
            
            if manager.is_connected(session_id):
                await manager.send_progress(session_id, payload)
                logger.info(f"[{session_id}] é¢„æ•´ç†æ•°æ®å·²æ¨é€å‰ç«¯")
                
        except Exception as e:
            logger.warning(f"[{session_id}] WebSocket æ¨é€å¼‚å¸¸: {e}")

        # 5. ä¿å­˜åˆ°æ•°æ®åº“ (å¯é€‰ï¼Œç”¨äºæ–­ç‚¹ç»­ä¼ )
        # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæš‚ä¸åŒ…å« DB ä¿å­˜ä»£ç ï¼Œç”± Controller å±‚å¤„ç†æˆ–åœ¨æ­¤å¤„æ·»åŠ  Model ä¿å­˜é€»è¾‘

        return {
            "preorganized_case": preorganized_result,
            "status": "preorganization_completed"
        }

    except Exception as e:
        logger.error(f"[{session_id}] é¢„æ•´ç†å¤±è´¥: {e}", exc_info=True)
        await send_ws_progress(session_id, "preorganize", "failed", f"å¤±è´¥: {str(e)}", 0)
        return {"error": str(e), "status": "failed"}


async def assemble_case_rules_node(state: LitigationAnalysisState) -> Dict[str, Any]:
    """èŠ‚ç‚¹3: ç»„è£…è§„åˆ™"""
    session_id = state['session_id']
    # å¦‚æœæ²¡æœ‰åœºæ™¯ï¼ˆé˜¶æ®µ1ï¼‰ï¼Œä½¿ç”¨é»˜è®¤åœºæ™¯
    scenario = state.get("analysis_scenario") or "pre_litigation"

    logger.info(f"[{session_id}] åŠ è½½è§„åˆ™åº“ (åœºæ™¯: {scenario})")

    # å‘é€è¿›åº¦æ›´æ–°
    await send_ws_progress(session_id, "assemble_case_rules", "processing", "æ­£åœ¨ç»„è£…æ¡ˆä»¶è§„åˆ™...", 0.25)

    try:
        assembler = CaseRuleAssembler()

        # é€‚é…ï¼šç¡®ä¿ä¼ å…¥ context çš„æ•°æ®æ˜¯æ‰å¹³æˆ–å¯è¯»çš„
        pre_data = state.get("preorganized_case", {})

        # æ·»åŠ ç±»å‹æ£€æŸ¥å’Œå®¹é”™å¤„ç†
        if not isinstance(pre_data, dict):
            logger.warning(f"[{session_id}] preorganized_case ä¸æ˜¯å­—å…¸ç±»å‹: {type(pre_data)}")
            pre_data = {}

        # ç¡®ä¿ enhanced_analysis_compatible æ˜¯å­—å…¸
        enhanced_info = pre_data.get("enhanced_analysis_compatible") if isinstance(pre_data, dict) else None
        if not isinstance(enhanced_info, dict):
            enhanced_info = {}

        rules = assembler.assemble_rules(
            package_id=state["case_package_id"],
            context={
                "case_type": state["case_type"],
                "case_position": state.get("case_position") or "unknown",
                "scenario": scenario,
                "preorganized": pre_data,
                "user_input": state.get("user_input"),
                # ä¼ é€’å¢å¼ºæ•°æ®è¾…åŠ©è§„åˆ™é€‰æ‹©
                "enhanced_info": enhanced_info
            }
        )

        # å‘é€å®Œæˆè¿›åº¦
        await send_ws_progress(session_id, "assemble_case_rules", "completed", "è§„åˆ™ç»„è£…å®Œæˆ", 0.35)

        return {"assembled_rules": rules, "status": "rules_assembled"}

    except Exception as e:
        logger.error(f"è§„åˆ™ç»„è£…å¤±è´¥: {e}")
        # è§„åˆ™ç»„è£…å¤±è´¥ä¸åº”ç†”æ–­ï¼Œè¿”å›ç©ºè§„åˆ™å³å¯
        await send_ws_progress(session_id, "assemble_case_rules", "failed", f"è§„åˆ™ç»„è£…å¤±è´¥: {str(e)}", 0.35)
        return {"assembled_rules": [], "status": "rules_failed_ignorable"}
# backend/app/services/litigation_analysis/workflow.py
# Part 2: Analysis Nodes, Drafting, and Graph Construction

async def analyze_evidence_node(state: LitigationAnalysisState) -> Dict[str, Any]:
    """èŠ‚ç‚¹4: è¯æ®åˆ†æ"""
    session_id = state['session_id']
    logger.info(f"[{session_id}] å¼€å§‹åˆ†æè¯æ®")

    # å‘é€è¿›åº¦æ›´æ–°
    await send_ws_progress(session_id, "analyze_evidence", "processing", "æ­£åœ¨åˆ†æè¯æ®...", 0.45)

    try:
        analyzer = EvidenceAnalyzer()

        # æ•°æ®é€‚é…ï¼šå°† document_summaries è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ä¾›åˆ†æå™¨ä½¿ç”¨
        pre_data = state.get("preorganized_case", {})

        # æ·»åŠ ç±»å‹æ£€æŸ¥
        if not isinstance(pre_data, dict):
            logger.warning(f"[{session_id}] preorganized_case ä¸æ˜¯å­—å…¸ç±»å‹: {type(pre_data)}")
            doc_summaries = {}
        else:
            doc_summaries = pre_data.get("document_summaries", {})

        # ç¡®ä¿ doc_summaries æ˜¯å­—å…¸
        if not isinstance(doc_summaries, dict):
            logger.warning(f"[{session_id}] document_summaries ä¸æ˜¯å­—å…¸ç±»å‹: {type(doc_summaries)}")
            doc_summaries = {}

        # æ„é€  EvidenceAnalyzer æœŸæœ›çš„è¾“å…¥æ ¼å¼
        # å‡è®¾ EvidenceAnalyzer æ¥å— list å½¢å¼çš„æ–‡æ¡£ä¿¡æ¯
        formatted_docs = {
            "document_analyses": [
                {
                    "file_name": v.get("document_title", k), # ä¼˜å…ˆç”¨æ ‡é¢˜
                    "file_type": v.get("document_subtype", "unknown"),
                    "content_summary": v.get("summary", ""),
                    "key_dates": v.get("key_dates", [])
                }
                for k, v in doc_summaries.items()
            ]
        }

        analysis = await analyzer.analyze(
            documents=formatted_docs,
            case_type=state["case_type"],
            context={
                "rules": state.get("assembled_rules", []),
                "scenario": state.get("analysis_scenario", "pre_litigation")
            }
        )

        # å‘é€å®Œæˆè¿›åº¦
        await send_ws_progress(session_id, "analyze_evidence", "completed", "è¯æ®åˆ†æå®Œæˆ", 0.55)

        return {"evidence_analysis": analysis, "status": "evidence_analyzed"}

    except Exception as e:
        logger.error(f"è¯æ®åˆ†æå¤±è´¥: {e}")
        await send_ws_progress(session_id, "analyze_evidence", "failed", f"è¯æ®åˆ†æå¤±è´¥: {str(e)}", 0.55)
        return {"error": f"è¯æ®åˆ†æå¤±è´¥: {str(e)}", "status": "failed"}


async def multi_model_analyze_node(state: LitigationAnalysisState) -> Dict[str, Any]:
    """èŠ‚ç‚¹5: ç»¼åˆæ¨æ¼” (è°ƒç”¨å¤šæ¨¡å‹)"""
    session_id = state['session_id']
    logger.info(f"[{session_id}] å¼€å§‹å¤šæ¨¡å‹ç»¼åˆæ¨æ¼”")

    # å‘é€è¿›åº¦
    await send_ws_progress(session_id, "multi_model_analyze", "processing", "AI æ­£åœ¨è¿›è¡Œå¤šæ¨¡å‹æ·±åº¦æ¨æ¼”...", 0.1)

    try:
        # 1. æ„å»ºä¸Šä¸‹æ–‡ (å·²åŒ…å«æ¡ˆä»¶å…¨æ™¯å’Œäº‰è®®ç„¦ç‚¹)
        # æ³¨æ„ï¼šenhanced_dataï¼ˆæ¡ˆä»¶å…¨æ™¯ï¼‰å·²è¢« _build_litigation_context æ•´åˆè¿› context
        context = _build_litigation_context(state)

        # 2. åˆå§‹åŒ–åˆ†æå™¨ (åœ¨æ­¤å¤„ä¼ å…¥æ¨¡å¼é…ç½®)
        analyzer = MultiModelAnalyzer(
            mode=state.get('analysis_mode', 'multi'),
            selected_model=state.get('selected_model')
        )

        # 3. æ‰§è¡Œåˆ†æ
        # âœ… ä¿®å¤ï¼šç§»é™¤é”™è¯¯çš„å…³é”®å­—å‚æ•°ï¼Œæ­£ç¡®æ˜ å°„å·²æœ‰å‚æ•°
        results = await analyzer.analyze_parallel(
            context=context,
            rules=state.get("assembled_rules", []),
            session_id=session_id,
            case_type=state["case_type"],
            case_position=state["case_position"],
            # ä¼ å…¥çœŸæ­£çš„è¯æ®åˆ†æç»“æœï¼ˆéæ¡ˆä»¶å…¨æ™¯ï¼‰
            evidence_analysis=state.get("evidence_analysis", {}),
            # ä¼ å…¥åˆ†æåœºæ™¯
            scenario=state.get("analysis_scenario", "pre_litigation")
        )

        await send_ws_progress(session_id, "multi_model_analyze", "completed", "æ¨æ¼”å®Œæˆ", 1.0)

        return {
            "model_results": results,
            "status": "model_analyzed"
        }
    except Exception as e:
        logger.error(f"æ¨¡å‹æ¨æ¼”å¤±è´¥: {e}", exc_info=True)
        # å¤±è´¥æ—¶å‘é€è¿›åº¦é€šçŸ¥
        await send_ws_progress(session_id, "multi_model_analyze", "failed", f"æ¨æ¼”å¤±è´¥: {str(e)}", 0)
        return {"error": f"æ¨¡å‹æ¨æ¼”å¤±è´¥: {str(e)}", "status": "failed"}


async def generate_strategies_node(state: LitigationAnalysisState) -> Dict[str, Any]:
    """èŠ‚ç‚¹6: ç”Ÿæˆç­–ç•¥ï¼ˆå¢å¼ºç‰ˆï¼šå®¹é”™å¤„ç†ï¼‰"""
    session_id = state['session_id']
    logger.info(f"[{session_id}] å¼€å§‹ç”Ÿæˆè¯‰è®¼ç­–ç•¥")

    # å‘é€è¿›åº¦æ›´æ–°
    await send_ws_progress(session_id, "generate_strategies", "processing", "æ­£åœ¨ç”Ÿæˆè¯‰è®¼ç­–ç•¥...", 0.75)

    try:
        # 1. æ£€æŸ¥ä¸Šæ¸¸æ˜¯å¦å¤±è´¥
        model_results = state.get("model_results", {})
        if model_results.get("status") == "failed" or "error" in model_results:
            logger.warning(f"[{session_id}] ä¸Šæ¸¸åˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ç­–ç•¥")
            strategies = _get_basic_strategies_for_failed_analysis(
                state.get("case_type", "æœªçŸ¥æ¡ˆä»¶"),
                state.get("analysis_scenario", "pre_litigation")
            )
        else:
            # 2. æ­£å¸¸æµç¨‹
            generator = StrategyGenerator()
            strategies = await generator.generate(
                case_strength=model_results,
                evidence=state.get("evidence_analysis", {}),
                case_type=state["case_type"],
                case_position=state["case_position"],
                scenario=state["analysis_scenario"]
            )

        # å‘é€å®Œæˆè¿›åº¦
        await send_ws_progress(session_id, "generate_strategies", "completed", "ç­–ç•¥ç”Ÿæˆå®Œæˆ", 0.85)

        return {
            "strategies": strategies,
            "status": "strategies_generated"
        }
    except Exception as e:
        logger.error(f"ç­–ç•¥ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        # è¿”å›åŸºç¡€ç­–ç•¥è€Œéé”™è¯¯ï¼Œé¿å…å·¥ä½œæµç†”æ–­
        strategies = _get_basic_strategies_for_failed_analysis(
            state.get("case_type", "æœªçŸ¥æ¡ˆä»¶"),
            state.get("analysis_scenario", "pre_litigation")
        )
        await send_ws_progress(session_id, "generate_strategies", "completed", "ç­–ç•¥ç”Ÿæˆå®Œæˆï¼ˆåŸºç¡€ç‰ˆï¼‰", 0.85)
        return {
            "strategies": strategies,
            "status": "strategies_generated_fallback"
        }


def _get_basic_strategies_for_failed_analysis(case_type: str, scenario: str) -> List[Dict]:
    """å½“åˆ†æå¤±è´¥æ—¶è¿”å›çš„åŸºç¡€ç­–ç•¥"""
    if scenario == "defense":
        return [{
            "strategy_id": "BASIC_DEF_01",
            "title": "å®¡æŸ¥ææ–™å¹¶å‡†å¤‡ç­”è¾©",
            "type": "balanced",
            "description": f"é’ˆå¯¹ã€{case_type}ã€‘æ¡ˆä»¶ï¼Œå»ºè®®é¦–å…ˆä»”ç»†å®¡æŸ¥åŸå‘Šæäº¤çš„ææ–™ã€‚",
            "steps": [
                {"step_name": "æ ¸å¯¹èµ·è¯‰çŠ¶", "description": "æ£€æŸ¥åŸå‘Šä¸»å¼ çš„äº‹å®å’Œè¯æ®", "executor": "å¾‹å¸ˆ", "deadline": "æ”¶åˆ°å3æ—¥å†…"},
                {"step_name": "å‡†å¤‡ç­”è¾©çŠ¶", "description": "é’ˆå¯¹åŸå‘Šä¸»å¼ é€ä¸€ç­”è¾©", "executor": "å¾‹å¸ˆ", "deadline": "ç­”è¾©æœŸå†…"}
            ],
            "expected_outcome": "æœ‰æ•ˆæŠ—è¾©",
            "risk_mitigation": "é¿å…ç¼ºå¸­å®¡åˆ¤",
            "recommendation_score": 5
        }]
    else:
        return [{
            "strategy_id": "BASIC_PRE_01",
            "title": "å®Œå–„è¯æ®å‡†å¤‡",
            "type": "conservative",
            "description": f"é’ˆå¯¹ã€{case_type}ã€‘æ¡ˆä»¶ï¼Œå»ºè®®é¦–å…ˆå®Œå–„è¯æ®é“¾ã€‚",
            "steps": [
                {"step_name": "æ¢³ç†è¯æ®", "description": "æŒ‰æ³•å¾‹è¦ä»¶æ•´ç†è¯æ®", "executor": "å½“äº‹äºº", "deadline": "ç«‹å³"},
                {"step_name": "æ³•å¾‹å’¨è¯¢", "description": "å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆ", "executor": "å½“äº‹äºº", "deadline": "5æ—¥å†…"}
            ],
            "expected_outcome": "æ˜ç¡®è¯‰è®¼æ–¹å‘",
            "risk_mitigation": "é¿å…è¯æ®ä¸è¶³",
            "recommendation_score": 4
        }]


async def generate_drafts_node(state: LitigationAnalysisState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹7: ç”Ÿæˆæ³•å¾‹æ–‡ä¹¦è‰ç¨¿
    """
    session_id = state['session_id']
    case_position = state.get('case_position')
    analysis_scenario = state.get('analysis_scenario')

    # å¦‚æœä¿¡æ¯ä¸å…¨ï¼Œè·³è¿‡
    if not case_position or not analysis_scenario:
        return {"draft_documents": [], "status": "drafts_skipped"}

    logger.info(f"[{session_id}] å¼€å§‹ç”Ÿæˆæ–‡ä¹¦è‰ç¨¿ (è§’è‰²: {case_position}, åœºæ™¯: {analysis_scenario})")

    try:
        await send_ws_progress(session_id, "generate_drafts", "processing", "æ­£åœ¨ç”Ÿæˆæ³•å¾‹æ–‡ä¹¦...", 0.1)

        # åŠ¨æ€å¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
        from app.services.document_drafting.agents.document_drafter import DocumentDrafterAgent
        from app.services.document_templates import TemplateManager

        # ç¡®å®šéœ€è¦çš„æ–‡ä¹¦ç±»å‹
        document_types = _get_required_document_types(case_position, analysis_scenario)
        
        if not document_types:
            return {"draft_documents": [], "status": "no_drafts_needed"}

        drafter = DocumentDrafterAgent()
        template_manager = TemplateManager()
        draft_documents = []

        # å‡†å¤‡æ•°æ®æº
        analysis_result = _build_drafting_analysis_result(state)
        reference_content = _build_reference_content(state)

        for idx, doc_type_info in enumerate(document_types, 1):
            doc_type = doc_type_info['type']
            doc_name = doc_type_info['name']
            
            try:
                # è·å–æ¨¡æ¿
                template_content = await template_manager.get_template(doc_type)
                if not template_content:
                    continue

                # ç”Ÿæˆ
                content, metadata = drafter.draft_with_template(
                    analysis_result=analysis_result,
                    template_content=template_content,
                    strategy={"mode": "template_rewrite", "temperature": 0.3},
                    reference_content=reference_content
                )

                draft_documents.append({
                    "document_type": doc_type,
                    "document_name": doc_name,
                    "content": content,
                    "generated_at": datetime.now().isoformat()
                })
                
                # è¿›åº¦æ›´æ–°
                await send_ws_progress(
                    session_id, "generate_drafts", "processing", 
                    f"å·²ç”Ÿæˆ: {doc_name}", 0.1 + (idx/len(document_types))*0.8
                )

            except Exception as e:
                logger.error(f"æ–‡ä¹¦ {doc_name} ç”Ÿæˆå¤±è´¥: {e}")

        await send_ws_progress(session_id, "generate_drafts", "completed", "æ–‡ä¹¦ç”Ÿæˆå®Œæˆ", 1.0)
        
        return {
            "draft_documents": draft_documents,
            "status": "drafts_generated"
        }

    except Exception as e:
        logger.error(f"æ–‡ä¹¦ç”ŸæˆèŠ‚ç‚¹å¼‚å¸¸: {e}")
        return {"draft_documents": [], "status": "drafts_failed"}


async def generate_report_node(state: LitigationAnalysisState) -> Dict[str, Any]:
    """èŠ‚ç‚¹8: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
    session_id = state['session_id']
    logger.info(f"[{session_id}] ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")

    # å‘é€è¿›åº¦æ›´æ–°
    await send_ws_progress(session_id, "generate_report", "processing", "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...", 0.92)

    try:
        generator = ReportGenerator()

        # æå–æ¨¡å‹æ‘˜è¦
        model_res = state.get("model_results", {})
        final_summary = ""
        if isinstance(model_res, dict) and "final_result" in model_res:
             final_summary = model_res["final_result"].get("summary", "")

        report_data = {
            "scenario": state["analysis_scenario"],
            "case_summary": final_summary,
            "rules": state.get("assembled_rules", []),
            "evidence_analysis": state.get("evidence_analysis"),
            "timeline": state.get("timeline"),
            "model_results": model_res,
            "strategies": state.get("strategies"),
            "draft_documents": state.get("draft_documents", []),
            "case_type": state["case_type"],
            "case_position": state["case_position"]
        }

        report_md, report_json = generator.generate(report_data)

        # å‘é€å®Œæˆè¿›åº¦
        await send_ws_progress(session_id, "generate_report", "completed", "æŠ¥å‘Šç”Ÿæˆå®Œæˆ", 0.98)

        return {
            "final_report": report_md,
            "report_json": report_json,
            "status": "completed"
        }
    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        await send_ws_progress(session_id, "generate_report", "failed", f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}", 0.98)
        return {"error": str(e), "status": "failed"}


# ==================== è¾…åŠ©é€»è¾‘ï¼šæ–‡ä¹¦ç”Ÿæˆæ”¯æŒ ====================

def _get_required_document_types(position: str, scenario: str) -> List[Dict]:
    """ç¡®å®šæ–‡ä¹¦ç±»å‹"""
    mapping = {
        ("plaintiff", "pre_litigation"): [
            {"type": "civil_complaint", "name": "æ°‘äº‹èµ·è¯‰çŠ¶"},
            {"type": "evidence_list", "name": "è¯æ®æ¸…å•"}
        ],
        ("defendant", "defense"): [
            {"type": "defense_statement", "name": "æ°‘äº‹ç­”è¾©çŠ¶"}
        ],
        ("applicant", "arbitration"): [
            {"type": "arbitration_application", "name": "ä»²è£ç”³è¯·ä¹¦"}
        ]
    }
    return mapping.get((position, scenario), [])

def _build_drafting_analysis_result(state: LitigationAnalysisState) -> Dict:
    """æ„é€ æ–‡ä¹¦èµ·è‰è¾“å…¥æ•°æ®"""
    pre_data = state.get("preorganized_case", {})
    enhanced = pre_data.get("enhanced_analysis_compatible", {})
    
    return {
        "case_type": state.get("case_type"),
        "case_position": state.get("case_position"),
        "parties": enhanced.get("parties", []), # é€‚é…æ–°ç»“æ„
        "timeline": enhanced.get("timeline", []),
        "case_summary": enhanced.get("transaction_summary", ""),
        "claims": {}, # éœ€è¿›ä¸€æ­¥ä» strategies æå–
    }

def _build_reference_content(state: LitigationAnalysisState) -> str:
    """æ„é€ å‚è€ƒèµ„æ–™å­—ç¬¦ä¸²"""
    parts = []
    if state.get("user_input"):
        parts.append(f"ç”¨æˆ·é™ˆè¿°: {state['user_input']}")
    
    pre = state.get("preorganized_case", {})
    if "enhanced_analysis_compatible" in pre:
        summary = pre["enhanced_analysis_compatible"].get("transaction_summary", "")
        parts.append(f"æ¡ˆä»¶ç»¼è¿°: {summary}")
        
    return "\n\n".join(parts)

def _build_litigation_context(state: LitigationAnalysisState) -> str:
    """
    æ„é€ å¤šæ¨¡å‹åˆ†æçš„ Context (å¢å¼ºç‰ˆ)

    ç¡®ä¿åŒ…å«å®Œæ•´çš„æ¡ˆä»¶äº‹å®ä¿¡æ¯ï¼š
    - æ¡ˆä»¶æ‘˜è¦
    - æ–‡æ¡£åˆ—è¡¨åŠè¯¦ç»†æ‘˜è¦
    - è¯æ®åˆ†æè¦ç‚¹
    - è§„åˆ™åº“åŒ¹é…ç»“æœ
    """
    parts = []

    # ==================== 1. åŸºç¡€ä¿¡æ¯ ====================
    parts.append("=" * 60)
    parts.append("ã€æ¡ˆä»¶åŸºç¡€ä¿¡æ¯ã€‘")
    parts.append(f"æ¡ˆä»¶ç±»å‹: {state['case_type']}")
    parts.append(f"æˆ‘æ–¹åœ°ä½: {state.get('case_position', 'æœªçŸ¥')}")
    parts.append(f"åˆ†æåœºæ™¯: {state.get('analysis_scenario', 'pre_litigation')}")

    if state.get("user_input"):
        parts.append(f"\nç”¨æˆ·é™ˆè¿°:\n{state['user_input']}")

    # ==================== 2. æ¡ˆä»¶å…¨æ™¯æ‘˜è¦ ====================
    pre = state.get("preorganized_case", {})
    if pre and isinstance(pre, dict):
        # æå–æ‘˜è¦ï¼ˆPre-org Summaryï¼‰
        summary = pre.get("summary", "")
        if summary:
            parts.append("\n" + "=" * 60)
            parts.append("ã€æ¡ˆæƒ…æ‘˜è¦ã€‘")
            parts.append(summary)

        # æå–å¢å¼ºåˆ†ææ•°æ®ï¼ˆæ¡ˆä»¶å…¨æ™¯ï¼‰
        enhanced = pre.get("enhanced_analysis_compatible", {})
        if enhanced and isinstance(enhanced, dict):
            trans_summary = enhanced.get("transaction_summary", "")
            if trans_summary:
                parts.append("\nã€äº¤æ˜“å…¨æ™¯ã€‘")
                parts.append(trans_summary)

            dispute_focus = enhanced.get("dispute_focus", "")
            if dispute_focus:
                parts.append("\nã€äº‰è®®ç„¦ç‚¹ã€‘")
                parts.append(dispute_focus)

            # ====== æ–°å¢ï¼šä¸»ä½“ç”»åƒ ======
            parties = enhanced.get("parties", [])
            if parties and isinstance(parties, list):
                parts.append("\nã€ä¸»ä½“ç”»åƒã€‘")
                for party in parties:
                    if isinstance(party, dict):
                        name = party.get("name", "æœªçŸ¥")
                        role = party.get("role", "æœªçŸ¥")
                        description = party.get("description", "")
                        parts.append(f"- {name} ({role})")
                        if description:
                            parts.append(f"  {description}")

            # ====== æ–°å¢ï¼šå®Œæ•´æ—¶é—´çº¿ ======
            timeline = enhanced.get("timeline", [])
            if timeline and isinstance(timeline, list):
                parts.append("\nã€æ¡ˆä»¶æ—¶é—´çº¿ã€‘")
                for event in timeline:
                    if isinstance(event, dict):
                        date = event.get("date", "")
                        description = event.get("description", "")
                        if date or description:
                            parts.append(f"- {date}: {description}")

    # ==================== 3. æ–‡æ¡£è¯¦ç»†æ‘˜è¦ ====================
    if pre and isinstance(pre, dict):
        doc_summaries = pre.get("document_summaries", {})
        if doc_summaries and isinstance(doc_summaries, dict) and len(doc_summaries) > 0:
            parts.append("\n" + "=" * 60)
            parts.append(f"ã€æ–‡æ¡£è¯æ®è¯¦æƒ…ã€‘(å…± {len(doc_summaries)} ä»½)")

            for file_id, doc_info in doc_summaries.items():
                if not isinstance(doc_info, dict):
                    continue

                doc_title = doc_info.get("document_title", doc_info.get("file_name", file_id))
                doc_type = doc_info.get("document_subtype", doc_info.get("file_type", "æœªçŸ¥"))
                summary = doc_info.get("summary", "")
                key_facts = doc_info.get("key_facts", [])
                key_dates = doc_info.get("key_dates", [])
                key_amounts = doc_info.get("key_amounts", [])
                raw_preview = doc_info.get("raw_preview", "")  # æ–°å¢ï¼šåŸæ–‡é¢„è§ˆ

                parts.append(f"\n--- {doc_title} ({doc_type}) ---")

                if summary:
                    parts.append(f"æ‘˜è¦: {summary}")

                if key_facts:
                    parts.append("å…³é”®äº‹å®:")
                    for fact in key_facts:  # ç§»é™¤ [:10] é™åˆ¶ï¼Œå…¨é‡æå–
                        parts.append(f"  â€¢ {fact}")

                if key_dates:
                    parts.append("å…³é”®æ—¥æœŸ:")
                    for date in key_dates:  # ç§»é™¤ [:10] é™åˆ¶
                        parts.append(f"  â€¢ {date}")

                if key_amounts:
                    parts.append("å…³é”®é‡‘é¢:")
                    for amount in key_amounts:  # ç§»é™¤ [:10] é™åˆ¶
                        parts.append(f"  â€¢ {amount}")

                # ====== æ–°å¢ï¼šåŸæ–‡é¢„è§ˆ ======
                if raw_preview:
                    parts.append(f"\nåŸæ–‡é¢„è§ˆ (å‰3000å­—):")
                    parts.append(raw_preview)

    # ==================== 4. è¯æ®åˆ†æå‘ç° ====================
    evidence_analysis = state.get("evidence_analysis", {})
    if evidence_analysis and isinstance(evidence_analysis, dict):
        parts.append("\n" + "=" * 60)
        parts.append("ã€è¯æ®åˆ†æå‘ç°ã€‘")

        analysis_points = evidence_analysis.get("analysis_points", [])
        if analysis_points and isinstance(analysis_points, list):
            parts.append(f"å‘ç° {len(analysis_points)} ä¸ªè¯æ®é—®é¢˜:")
            for point in analysis_points:  # ç§»é™¤ [:15] é™åˆ¶
                if isinstance(point, dict):
                    desc = point.get("description", point.get("issue", str(point)))
                    parts.append(f"  â€¢ {desc}")
                else:
                    parts.append(f"  â€¢ {point}")

        admissibility = evidence_analysis.get("admissibility_assessment", "")
        if admissibility:
            parts.append(f"\nè¯æ®å¯é‡‡æ€§è¯„ä¼°: {admissibility}")

        evidence_gaps = evidence_analysis.get("evidence_gaps", [])
        if evidence_gaps:
            parts.append("\nè¯æ®ç¼ºå£:")
            for gap in evidence_gaps:  # ç§»é™¤ [:10] é™åˆ¶
                parts.append(f"  â€¢ {gap}")

    # ==================== 5. åŸå§‹æ–‡æ¡£å†…å®¹è¡¥å……ï¼ˆå¯é€‰ï¼‰ ====================
    raw_docs = state.get("raw_documents", [])
    if raw_docs and isinstance(raw_docs, list):
        parts.append("\n" + "=" * 60)
        parts.append("ã€åŸå§‹æ–‡æ¡£å†…å®¹æ‘˜å½•ã€‘")

        for doc in raw_docs[:3]:  # æœ€å¤šå–å‰3ä¸ªæ–‡æ¡£
            if hasattr(doc, 'content') and doc.content:
                content_preview = doc.content[:2000] if len(doc.content) > 2000 else doc.content
                file_name = getattr(doc, 'file_name', doc.file_id)
                parts.append(f"\n--- {file_name} (å†…å®¹æ‘˜å½•) ---")
                parts.append(content_preview)
                parts.append("...(å†…å®¹å·²æˆªæ–­)")

    # ==================== 6. è§„åˆ™åº“åŒ¹é…ç»“æœï¼ˆä¾›å‚è€ƒï¼‰====================
    rules = state.get("assembled_rules", [])
    if rules and isinstance(rules, list):
        parts.append("\n" + "=" * 60)
        parts.append(f"ã€é€‚ç”¨æ³•å¾‹è§„åˆ™ã€‘(å…± {len(rules)} æ¡)")
        for i, rule in enumerate(rules, 1):  # ç§»é™¤ [:10] é™åˆ¶
            parts.append(f"{i}. {rule}")

    # åˆå¹¶æ‰€æœ‰éƒ¨åˆ†
    full_context = "\n".join(parts)

    # è®°å½•æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
    logger.info(f"[{state.get('session_id')}] æ„å»ºåˆ†æ Context | é•¿åº¦: {len(full_context)} å­—ç¬¦")

    return full_context


# ==================== å›¾æ„å»ºä¸æ‰§è¡Œ ====================

def build_litigation_analysis_graph(skip_preorganization: bool = False, skip_drafts: bool = False):
    """
    æ„å»º LangGraph (ä¿®å¤ç‰ˆ)
    
    ä¿®å¤: è§£å†³ Stage 2 æ¨¡å¼ä¸‹å­¤å²›èŠ‚ç‚¹å¯¼è‡´çš„ "Node not reachable" é”™è¯¯ã€‚
    """
    builder = StateGraph(LitigationAnalysisState)

    # ==================== 1. æ³¨å†Œæ ¸å¿ƒåˆ†æèŠ‚ç‚¹ (æ‰€æœ‰é˜¶æ®µéƒ½éœ€è¦) ====================
    builder.add_node("assemble_case_rules", assemble_case_rules_node)
    builder.add_node("analyze_evidence", analyze_evidence_node)
    builder.add_node("multi_model_analyze", multi_model_analyze_node)
    builder.add_node("generate_strategies", generate_strategies_node)

    # åªåœ¨éœ€è¦æ—¶æ³¨å†Œæ–‡ä¹¦ç”ŸæˆèŠ‚ç‚¹
    if not skip_drafts:
        builder.add_node("generate_drafts", generate_drafts_node)

    builder.add_node("generate_report", generate_report_node)

    # ==================== 2. æ ¹æ®é˜¶æ®µæ³¨å†Œé¢„å¤„ç†èŠ‚ç‚¹ ====================
    if not skip_preorganization:
        # ä»…åœ¨é˜¶æ®µ 1 (å…¨æµç¨‹) æ·»åŠ è¿™äº›èŠ‚ç‚¹
        builder.add_node("process_documents", process_documents_node)
        builder.add_node("preorganize_case", preorganize_case_node)

        # å®šä¹‰é˜¶æ®µ 1 çš„å…¥å£å’Œæµè½¬
        builder.set_entry_point("process_documents")
        builder.add_edge("process_documents", "preorganize_case")
        
        # é¢„æ•´ç† -> è§„åˆ™ç»„è£… (å¸¦ç†”æ–­)
        builder.add_conditional_edges(
            "preorganize_case", 
            check_error_status, 
            {"continue": "assemble_case_rules", "end": END}
        )
    else:
        # é˜¶æ®µ 2 (æ·±åº¦åˆ†æ)ï¼šè·³è¿‡é¢„æ•´ç†ï¼Œç›´æ¥ä»è§„åˆ™ç»„è£…å¼€å§‹
        builder.set_entry_point("assemble_case_rules")

    # ==================== 3. å®šä¹‰æ ¸å¿ƒåˆ†ææµè½¬ ====================
    
    # è§„åˆ™ç»„è£… -> è¯æ®åˆ†æ
    builder.add_edge("assemble_case_rules", "analyze_evidence")
    
    # è¯æ®åˆ†æ -> å¤šæ¨¡å‹æ¨æ¼” (å¸¦ç†”æ–­)
    builder.add_conditional_edges(
        "analyze_evidence", 
        check_error_status,
        {"continue": "multi_model_analyze", "end": END}
    )
                                  
    # å¤šæ¨¡å‹æ¨æ¼” -> ç­–ç•¥ç”Ÿæˆ (å¸¦ç†”æ–­)
    builder.add_conditional_edges(
        "multi_model_analyze", 
        check_error_status,
        {"continue": "generate_strategies", "end": END}
    )

    # ==================== 4. å®šä¹‰åç»­æµè½¬ (æ–‡ä¹¦ä¸æŠ¥å‘Š) ====================

    if skip_drafts:
        # è·³è¿‡æ–‡ä¹¦ï¼Œç›´æ¥ç”ŸæˆæŠ¥å‘Š
        builder.add_edge("generate_strategies", "generate_report")
    else:
        # ç”Ÿæˆæ–‡ä¹¦ -> ç”ŸæˆæŠ¥å‘Š
        builder.add_edge("generate_strategies", "generate_drafts")
        builder.add_edge("generate_drafts", "generate_report")

    # ç»“æŸ
    builder.add_edge("generate_report", END)

    memory = MemorySaver()
    return builder.compile(checkpointer=memory)


async def run_litigation_analysis_workflow(
    session_id: str,
    user_input: Optional[str],
    document_paths: List[str],
    case_package_id: str,
    case_type: str,
    case_position: Optional[str], # Allow None for stage 1
    analysis_scenario: Optional[str] = "pre_litigation",
    preorganized_case: Optional[Dict[str, Any]] = None,
    analysis_mode: str = "multi",
    selected_model: Optional[str] = None,
    skip_preorganization: bool = False,
    skip_drafts: bool = False
) -> Dict[str, Any]:
    """
    å·¥ä½œæµå…¥å£
    """
    logger.info(f"[{session_id}] å¯åŠ¨å·¥ä½œæµ")

    initial_state: LitigationAnalysisState = {
        "session_id": session_id,
        "user_input": user_input,
        "document_paths": document_paths,
        "case_package_id": case_package_id,
        "case_type": case_type,
        "case_position": case_position,
        "analysis_scenario": analysis_scenario,
        "analysis_mode": analysis_mode,
        "selected_model": selected_model,
        "preorganized_case": preorganized_case,
        
        "raw_documents": None,
        "assembled_rules": None,
        "timeline": None,
        "evidence_analysis": None,
        "model_results": None,
        "strategies": None,
        "draft_documents": None,
        "final_report": None,
        "report_json": None,
        "status": "started",
        "error": None
    }

    app = build_litigation_analysis_graph(skip_preorganization, skip_drafts)
    
    config = {"configurable": {"thread_id": session_id}}
    
    try:
        result = await app.ainvoke(initial_state, config)
        return result
    except Exception as e:
        logger.error(f"[{session_id}] å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {e}", exc_info=True)
        return {"error": str(e), "status": "crashed"}

# Stage 2 å…¥å£ä¿æŒç±»ä¼¼é€»è¾‘ï¼Œåªéœ€è®¾ç½® skip_preorganization=True
# ==================== Stage 2 å…¥å£å‡½æ•° (è¡¥å…¨) ====================

async def run_stage2_analysis(
    session_id: str,
    preorganized_case: Dict[str, Any],
    case_position: str,
    analysis_scenario: str,
    case_package_id: str,
    case_type: str,
    user_input: Optional[str] = None,
    analysis_mode: str = "multi",
    selected_model: Optional[str] = None
) -> Dict[str, Any]:
    """
    æ‰§è¡Œé˜¶æ®µ2ï¼šå…¨æ¡ˆåˆ†æ

    è¿™æ˜¯ç”¨æˆ·ç¡®è®¤é¢„æ•´ç†æ•°æ®å¹¶é€‰æ‹©è§’è‰²å’Œåœºæ™¯åè°ƒç”¨çš„åˆ†ææµç¨‹ã€‚
    ç‰¹ç‚¹ï¼š
    1. è·³è¿‡æ–‡æ¡£å¤„ç†å’Œé¢„æ•´ç† (skip_preorganization=True)
    2. ç›´æ¥åˆ©ç”¨ä¼ å…¥çš„ preorganized_case
    3. æ ¹æ® case_position å’Œ analysis_scenario è¿›è¡Œæ·±åº¦æ¨æ¼”
    """
    logger.info(
        f"[{session_id}] å¯åŠ¨é˜¶æ®µ2åˆ†æ | "
        f"è§’è‰²: {case_position} | åœºæ™¯: {analysis_scenario}"
    )

    # ğŸ›¡ï¸ æ ¸å¿ƒä¿®å¤ï¼šé˜²é—ªé€€ç­‰å¾…
    # æ— è®ºä»»åŠ¡è·‘å¾—å¤šå¿«ï¼Œå…ˆç­‰å‰ç«¯æŠŠç”µè¯æ¥é€š
    from app.api.websocket import manager

    logger.info(f"[{session_id}] æ­£åœ¨ç­‰å¾…å‰ç«¯å»ºç«‹ WebSocket è¿æ¥...")
    websocket_connected = False

    for attempt in range(50):  # æœ€å¤šç­‰ 5 ç§’
        if manager.is_connected(session_id):
            logger.info(f"[{session_id}] âœ… WebSocket è¿æ¥å·²ç¡®è®¤ (å°è¯• {attempt + 1}/50)ï¼Œå¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼")
            websocket_connected = True
            break
        await asyncio.sleep(0.1)

    if not websocket_connected:
        logger.warning(f"[{session_id}] âš ï¸ WebSocket è¿æ¥è¶…æ—¶ï¼ˆ5ç§’ï¼‰ï¼Œä»»åŠ¡å°†ç»§ç»­æ‰§è¡Œä½†å¯èƒ½æ— æ³•æ¥æ”¶å®æ—¶è¿›åº¦")

    return await run_litigation_analysis_workflow(
        session_id=session_id,
        user_input=user_input,
        document_paths=[],  # é˜¶æ®µ2ä¸éœ€è¦é‡æ–°è¯»å–åŸå§‹æ–‡æ¡£è·¯å¾„
        case_package_id=case_package_id,
        case_type=case_type,
        case_position=case_position,
        analysis_scenario=analysis_scenario,
        preorganized_case=preorganized_case,
        analysis_mode=analysis_mode,
        selected_model=selected_model,
        skip_preorganization=True,  # å…³é”®ï¼šè·³è¿‡é¢„æ•´ç†èŠ‚ç‚¹ï¼Œç›´æ¥è¿›å…¥è§„åˆ™ç»„è£…
        skip_drafts=True  # å…³é”®ï¼šè·³è¿‡è‡ªåŠ¨æ–‡ä¹¦ç”Ÿæˆï¼Œç”±ç”¨æˆ·æ‰‹åŠ¨è§¦å‘
    )